{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755afe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05bdb780",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('radiomics_features_all_patients_TUMOR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ede86f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>T1c_diagnostics_Versions_PyRadiomics</th>\n",
       "      <th>T1c_diagnostics_Versions_Numpy</th>\n",
       "      <th>T1c_diagnostics_Versions_SimpleITK</th>\n",
       "      <th>T1c_diagnostics_Versions_PyWavelet</th>\n",
       "      <th>T1c_diagnostics_Versions_Python</th>\n",
       "      <th>T1c_diagnostics_Configuration_Settings</th>\n",
       "      <th>T1c_diagnostics_Configuration_EnabledImageTypes</th>\n",
       "      <th>T1c_diagnostics_Image-original_Hash</th>\n",
       "      <th>T1c_diagnostics_Image-original_Dimensionality</th>\n",
       "      <th>...</th>\n",
       "      <th>MD_original_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>MD_original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>MD_original_glszm_ZoneEntropy</th>\n",
       "      <th>MD_original_glszm_ZonePercentage</th>\n",
       "      <th>MD_original_glszm_ZoneVariance</th>\n",
       "      <th>MD_original_ngtdm_Busyness</th>\n",
       "      <th>MD_original_ngtdm_Coarseness</th>\n",
       "      <th>MD_original_ngtdm_Complexity</th>\n",
       "      <th>MD_original_ngtdm_Contrast</th>\n",
       "      <th>MD_original_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCSF-PDGM-0130_nifti</td>\n",
       "      <td>v3.1.0</td>\n",
       "      <td>1.23.5</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>3.9.22</td>\n",
       "      <td>{'minimumROIDimensions': 2, 'minimumROISize': ...</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>81ef47d2a31deb568bf23a399324afe391e19898</td>\n",
       "      <td>3D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208002</td>\n",
       "      <td>0.208002</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>8.876046e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCSF-PDGM-0046_nifti</td>\n",
       "      <td>v3.1.0</td>\n",
       "      <td>1.23.5</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>3.9.22</td>\n",
       "      <td>{'minimumROIDimensions': 2, 'minimumROISize': ...</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>ce2a05b786c95c45a3b6dfe67b4bd3b47d1a36a5</td>\n",
       "      <td>3D</td>\n",
       "      <td>...</td>\n",
       "      <td>2543.012756</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>7.748978</td>\n",
       "      <td>0.560357</td>\n",
       "      <td>7.375384e+00</td>\n",
       "      <td>0.153713</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>52593.855670</td>\n",
       "      <td>0.304477</td>\n",
       "      <td>9.420885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCSF-PDGM-0132_nifti</td>\n",
       "      <td>v3.1.0</td>\n",
       "      <td>1.23.5</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>3.9.22</td>\n",
       "      <td>{'minimumROIDimensions': 2, 'minimumROISize': ...</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>e6837ab578fa4f0f2321afe6f808cdd015b995cf</td>\n",
       "      <td>3D</td>\n",
       "      <td>...</td>\n",
       "      <td>3.659826</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>1.075500e+03</td>\n",
       "      <td>1.752623</td>\n",
       "      <td>0.047464</td>\n",
       "      <td>3.341956</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.493350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCSF-PDGM-0107_nifti</td>\n",
       "      <td>v3.1.0</td>\n",
       "      <td>1.23.5</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>3.9.22</td>\n",
       "      <td>{'minimumROIDimensions': 2, 'minimumROISize': ...</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>15b716c2bdac0f690e117aa8a956268648e74f78</td>\n",
       "      <td>3D</td>\n",
       "      <td>...</td>\n",
       "      <td>853.384800</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>7.153493</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>7.933386e+00</td>\n",
       "      <td>0.313949</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>9100.546126</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>3.794287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCSF-PDGM-0149_nifti</td>\n",
       "      <td>v3.1.0</td>\n",
       "      <td>1.23.5</td>\n",
       "      <td>2.5.0</td>\n",
       "      <td>1.6.0</td>\n",
       "      <td>3.9.22</td>\n",
       "      <td>{'minimumROIDimensions': 2, 'minimumROISize': ...</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>aeb6ea8e44b54092800c51b5c774131d335deb3f</td>\n",
       "      <td>3D</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>0.008787</td>\n",
       "      <td>1.694736e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1678 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PatientID T1c_diagnostics_Versions_PyRadiomics  \\\n",
       "0  UCSF-PDGM-0130_nifti                               v3.1.0   \n",
       "1  UCSF-PDGM-0046_nifti                               v3.1.0   \n",
       "2  UCSF-PDGM-0132_nifti                               v3.1.0   \n",
       "3  UCSF-PDGM-0107_nifti                               v3.1.0   \n",
       "4  UCSF-PDGM-0149_nifti                               v3.1.0   \n",
       "\n",
       "  T1c_diagnostics_Versions_Numpy T1c_diagnostics_Versions_SimpleITK  \\\n",
       "0                         1.23.5                              2.5.0   \n",
       "1                         1.23.5                              2.5.0   \n",
       "2                         1.23.5                              2.5.0   \n",
       "3                         1.23.5                              2.5.0   \n",
       "4                         1.23.5                              2.5.0   \n",
       "\n",
       "  T1c_diagnostics_Versions_PyWavelet T1c_diagnostics_Versions_Python  \\\n",
       "0                              1.6.0                          3.9.22   \n",
       "1                              1.6.0                          3.9.22   \n",
       "2                              1.6.0                          3.9.22   \n",
       "3                              1.6.0                          3.9.22   \n",
       "4                              1.6.0                          3.9.22   \n",
       "\n",
       "              T1c_diagnostics_Configuration_Settings  \\\n",
       "0  {'minimumROIDimensions': 2, 'minimumROISize': ...   \n",
       "1  {'minimumROIDimensions': 2, 'minimumROISize': ...   \n",
       "2  {'minimumROIDimensions': 2, 'minimumROISize': ...   \n",
       "3  {'minimumROIDimensions': 2, 'minimumROISize': ...   \n",
       "4  {'minimumROIDimensions': 2, 'minimumROISize': ...   \n",
       "\n",
       "  T1c_diagnostics_Configuration_EnabledImageTypes  \\\n",
       "0                                {'Original': {}}   \n",
       "1                                {'Original': {}}   \n",
       "2                                {'Original': {}}   \n",
       "3                                {'Original': {}}   \n",
       "4                                {'Original': {}}   \n",
       "\n",
       "        T1c_diagnostics_Image-original_Hash  \\\n",
       "0  81ef47d2a31deb568bf23a399324afe391e19898   \n",
       "1  ce2a05b786c95c45a3b6dfe67b4bd3b47d1a36a5   \n",
       "2  e6837ab578fa4f0f2321afe6f808cdd015b995cf   \n",
       "3  15b716c2bdac0f690e117aa8a956268648e74f78   \n",
       "4  aeb6ea8e44b54092800c51b5c774131d335deb3f   \n",
       "\n",
       "  T1c_diagnostics_Image-original_Dimensionality  ...  \\\n",
       "0                                            3D  ...   \n",
       "1                                            3D  ...   \n",
       "2                                            3D  ...   \n",
       "3                                            3D  ...   \n",
       "4                                            3D  ...   \n",
       "\n",
       "  MD_original_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                         0.208002   \n",
       "1                                      2543.012756   \n",
       "2                                         3.659826   \n",
       "3                                       853.384800   \n",
       "4                                         0.007016   \n",
       "\n",
       "  MD_original_glszm_SmallAreaLowGrayLevelEmphasis  \\\n",
       "0                                        0.208002   \n",
       "1                                        0.001269   \n",
       "2                                        0.009922   \n",
       "3                                        0.003132   \n",
       "4                                        0.007016   \n",
       "\n",
       "   MD_original_glszm_ZoneEntropy  MD_original_glszm_ZonePercentage  \\\n",
       "0                       2.321928                          0.000555   \n",
       "1                       7.748978                          0.560357   \n",
       "2                       2.750000                          0.042553   \n",
       "3                       7.153493                          0.557800   \n",
       "4                       2.321928                          0.008787   \n",
       "\n",
       "   MD_original_glszm_ZoneVariance MD_original_ngtdm_Busyness  \\\n",
       "0                    8.876046e+06                   0.000000   \n",
       "1                    7.375384e+00                   0.153713   \n",
       "2                    1.075500e+03                   1.752623   \n",
       "3                    7.933386e+00                   0.313949   \n",
       "4                    1.694736e+04                   0.000000   \n",
       "\n",
       "  MD_original_ngtdm_Coarseness MD_original_ngtdm_Complexity  \\\n",
       "0               1000000.000000                     0.000000   \n",
       "1                     0.001104                 52593.855670   \n",
       "2                     0.047464                     3.341956   \n",
       "3                     0.002135                  9100.546126   \n",
       "4               1000000.000000                     0.000000   \n",
       "\n",
       "  MD_original_ngtdm_Contrast  MD_original_ngtdm_Strength  \n",
       "0                   0.000000                    0.000000  \n",
       "1                   0.304477                    9.420885  \n",
       "2                   0.016476                    0.493350  \n",
       "3                   0.366337                    3.794287  \n",
       "4                   0.000000                    0.000000  \n",
       "\n",
       "[5 rows x 1678 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f3e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both CSVs\n",
    "df_radiomics = pd.read_csv('radiomics_features_all_patients_TUMOR.csv')\n",
    "df_metadata = pd.read_csv('UCSF-PDGM-metadata_v2.csv')\n",
    "\n",
    "# Standardize column names\n",
    "df_radiomics.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "df_metadata.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "# Strip and normalize IDs\n",
    "df_radiomics['PatientID'] = df_radiomics['PatientID'].astype(str).str.strip().str.replace('_nifti', '', regex=False).str.upper()\n",
    "df_metadata['PatientID'] = df_metadata['PatientID'].astype(str).str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b57162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Radiomics PatientIDs: 217\n",
      "🧾 Metadata PatientIDs: 501\n",
      "🔗 Common PatientIDs found after cleaning: 217\n"
     ]
    }
   ],
   "source": [
    "common_ids = set(df_radiomics['PatientID']) & set(df_metadata['PatientID'])\n",
    "\n",
    "print(\"🧾 Radiomics PatientIDs:\", df_radiomics['PatientID'].nunique())\n",
    "print(\"🧾 Metadata PatientIDs:\", df_metadata['PatientID'].nunique())\n",
    "print(\"🔗 Common PatientIDs found after cleaning:\", len(common_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48d73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged DataFrame shape: (217, 1693)\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_radiomics, df_metadata, on='PatientID', how='inner')\n",
    "print(\"✅ Merged DataFrame shape:\", df_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32073e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Merged CSV saved as 'merged_radiomics_metadata.csv'\n"
     ]
    }
   ],
   "source": [
    "df_merged.to_csv(\"merged_radiomics_metadata.csv\", index=False)\n",
    "print(\"📁 Merged CSV saved as 'merged_radiomics_metadata.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d1c8c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18075d47",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807fa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 200 Features:\n",
      " ['IDH', 'Age at MRI', 'PatientID', 'MGMT index']\n",
      "Class distribution before SMOTE:\n",
      " 1-dead 0-alive\n",
      "1    119\n",
      "0     98\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      " 1-dead 0-alive\n",
      "0    119\n",
      "1    119\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🔧 Training Voting Classifier...\n",
      "\n",
      "Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71        36\n",
      "           1       0.71      0.75      0.73        36\n",
      "\n",
      "    accuracy                           0.72        72\n",
      "   macro avg       0.72      0.72      0.72        72\n",
      "weighted avg       0.72      0.72      0.72        72\n",
      "\n",
      "\n",
      "🔧 Training Stacking Classifier...\n",
      "\n",
      "Stacking Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70        36\n",
      "           1       0.71      0.67      0.69        36\n",
      "\n",
      "    accuracy                           0.69        72\n",
      "   macro avg       0.70      0.69      0.69        72\n",
      "weighted avg       0.70      0.69      0.69        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mlpr data\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:41:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\mlpr data\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:41:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "d:\\mlpr data\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:41:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "\n",
    "# Step 1: Load merged data\n",
    "df = pd.read_csv('merged_radiomics_metadata.csv')\n",
    "\n",
    "# Step 2: Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"OS\", \"Survival_Category\"], errors=\"ignore\")\n",
    "if \"1-dead 0-alive\" in df.columns:\n",
    "    y = df[\"1-dead 0-alive\"]\n",
    "else:\n",
    "    raise ValueError(\"Target column '1-dead 0-alive' not found in the dataset.\")\n",
    "\n",
    "# Step 3: Encode categorical features\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Step 4: Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Step 5: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Step 6: Apply SMOTE\n",
    "print(\"Class distribution before SMOTE:\\n\", y.value_counts())\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_scaled, y)\n",
    "print(\"Class distribution after SMOTE:\\n\", pd.Series(y_smote).value_counts())\n",
    "\n",
    "# Step 7: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_smote, y_smote, test_size=0.3, stratify=y_smote, random_state=42\n",
    ")\n",
    "\n",
    "# Step 8: Define base models\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=8, random_state=42)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=10, max_depth=3, learning_rate=0.01,\n",
    "    subsample=0.8, colsample_bytree=0.8, use_label_encoder=False,\n",
    "    eval_metric='logloss', random_state=42\n",
    ")\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "# lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Step 9: Define ensemble models\n",
    "voting = VotingClassifier(estimators=[\n",
    "    (\"rf\", rf), (\"xgb\", xgb_clf), (\"logreg\", logreg)\n",
    "], voting=\"hard\")\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"xgb\", xgb_clf), (\"logreg\", logreg)],\n",
    "    final_estimator=LogisticRegression(max_iter=100)\n",
    ")\n",
    "\n",
    "# Step 10: Train and evaluate\n",
    "print(\"\\n🔧 Training Voting Classifier...\")\n",
    "voting.fit(X_train, y_train)\n",
    "y_pred_voting = voting.predict(X_test)\n",
    "print(\"\\nVoting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "\n",
    "print(\"\\n🔧 Training Stacking Classifier...\")\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking.predict(X_test)\n",
    "print(\"\\nStacking Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1debf707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-dead 0-alive                          1.000000\n",
      "WHO CNS Grade                           0.404754\n",
      "Age at MRI                              0.354230\n",
      "L1_original_firstorder_Skewness         0.233038\n",
      "SWI_original_gldm_DependenceVariance    0.203031\n",
      "                                          ...   \n",
      "L1_diagnostics_Image-original_Mean     -0.225585\n",
      "L1_original_firstorder_10Percentile    -0.234841\n",
      "ADC_original_firstorder_Kurtosis       -0.240387\n",
      "MGMT index                             -0.248263\n",
      "OS                                     -0.253029\n",
      "Name: 1-dead 0-alive, Length: 1461, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr(numeric_only=True)\n",
    "print(correlations[\"1-dead 0-alive\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2777fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87        36\n",
      "           1       0.86      0.89      0.88        36\n",
      "\n",
      "    accuracy                           0.88        72\n",
      "   macro avg       0.88      0.88      0.87        72\n",
      "weighted avg       0.88      0.88      0.87        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"\\nRandom Forest Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b74a1e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00        72\n",
      "   macro avg       1.00      1.00      1.00        72\n",
      "weighted avg       1.00      1.00      1.00        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devyansh\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [23:11:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=10, max_depth=3, learning_rate=0.1,\n",
    "    subsample=0.5, colsample_bytree=0.5, use_label_encoder=False,\n",
    "    eval_metric='logloss', random_state=42\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(\"\\nXGBoost Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20ee5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92        36\n",
      "           1       0.94      0.89      0.91        36\n",
      "\n",
      "    accuracy                           0.92        72\n",
      "   macro avg       0.92      0.92      0.92        72\n",
      "weighted avg       0.92      0.92      0.92        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=500)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print(\"\\nLogistic Regression Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff393de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.56      0.62        36\n",
      "           1       0.64      0.78      0.70        36\n",
      "\n",
      "    accuracy                           0.67        72\n",
      "   macro avg       0.68      0.67      0.66        72\n",
      "weighted avg       0.68      0.67      0.66        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "print(\"\\nSupport Vector Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8341bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      " 1-dead 0-alive\n",
      "1    119\n",
      "0     98\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      " 1-dead 0-alive\n",
      "0    119\n",
      "1    119\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🔧 Training Voting Classifier...\n",
      "\n",
      "Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        36\n",
      "           1       0.97      0.89      0.93        36\n",
      "\n",
      "    accuracy                           0.93        72\n",
      "   macro avg       0.93      0.93      0.93        72\n",
      "weighted avg       0.93      0.93      0.93        72\n",
      "\n",
      "\n",
      "🔧 Training Stacking Classifier...\n",
      "\n",
      "Stacking Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00        72\n",
      "   macro avg       1.00      1.00      1.00        72\n",
      "weighted avg       1.00      1.00      1.00        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Load merged data\n",
    "df = pd.read_csv('merged_radiomics_metadata.csv')\n",
    "\n",
    "# Step 2: Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"OS\", \"Survival_Category\"], errors=\"ignore\")\n",
    "if \"1-dead 0-alive\" in df.columns:\n",
    "    y = df[\"1-dead 0-alive\"]\n",
    "else:\n",
    "    raise ValueError(\"Target column '1-dead 0-alive' not found in the dataset.\")\n",
    "\n",
    "# Step 3: Encode categorical features\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Step 4: Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Step 5: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Step 6: Apply SMOTE\n",
    "print(\"Class distribution before SMOTE:\\n\", y.value_counts())\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_scaled, y)\n",
    "print(\"Class distribution after SMOTE:\\n\", pd.Series(y_smote).value_counts())\n",
    "\n",
    "# Step 7: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_smote, y_smote, test_size=0.3, stratify=y_smote, random_state=42\n",
    ")\n",
    "\n",
    "# Step 8: Define base models\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
    "svc = SVC(kernel='poly', C=1.0, probability=True, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Step 9: Define ensemble models\n",
    "voting = VotingClassifier(estimators=[\n",
    "    (\"rf\", rf), (\"svc\", svc), (\"logreg\", logreg), (\"lda\", lda)\n",
    "], voting=\"hard\")\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"svc\", svc), (\"logreg\", logreg), (\"lda\", lda)],\n",
    "    final_estimator=LogisticRegression(max_iter=100)\n",
    ")\n",
    "\n",
    "# Step 10: Train and evaluate\n",
    "print(\"\\n🔧 Training Voting Classifier...\")\n",
    "voting.fit(X_train, y_train)\n",
    "y_pred_voting = voting.predict(X_test)\n",
    "print(\"\\nVoting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_voting))\n",
    "\n",
    "print(\"\\n🔧 Training Stacking Classifier...\")\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking.predict(X_test)\n",
    "print(\"\\nStacking Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f2e85",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3b662",
   "metadata": {},
   "source": [
    "# Using LDA to reduce features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06adeea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      " 1-dead 0-alive\n",
      "1    119\n",
      "0     98\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      " 1-dead 0-alive\n",
      "0    119\n",
      "1    119\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🔎 Selecting Top 1693 Features using ANOVA F-test...\n",
      "\n",
      "📦 Training Voting Classifier with 1693 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devyansh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:776: UserWarning: k=1693 is greater than n_features=1692. All the features will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Voting Classifier Metrics:\n",
      "Accuracy: 0.9861111111111112\n",
      "Balanced Accuracy: 0.9861111111111112\n",
      "F1 Score: 0.9859154929577465\n",
      "Precision: 1.0\n",
      "Recall: 0.9722222222222222\n",
      "ROC-AUC: 1.0\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "📦 Training Stacking Classifier with 1693 features...\n",
      "📊 Stacking Classifier Metrics:\n",
      "Accuracy: 1.0\n",
      "Balanced Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "ROC-AUC: 1.0\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "🔎 Selecting Top 1600 Features using ANOVA F-test...\n",
      "\n",
      "📦 Training Voting Classifier with 1600 features...\n",
      "📊 Voting Classifier Metrics:\n",
      "Accuracy: 0.6388888888888888\n",
      "Balanced Accuracy: 0.6388888888888888\n",
      "F1 Score: 0.6388888888888888\n",
      "Precision: 0.6388888888888888\n",
      "Recall: 0.6388888888888888\n",
      "ROC-AUC: 0.7337962962962963\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "📦 Training Stacking Classifier with 1600 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devyansh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Stacking Classifier Metrics:\n",
      "Accuracy: 0.6944444444444444\n",
      "Balanced Accuracy: 0.6944444444444444\n",
      "F1 Score: 0.6944444444444444\n",
      "Precision: 0.6944444444444444\n",
      "Recall: 0.6944444444444444\n",
      "ROC-AUC: 0.7631172839506173\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "🔎 Selecting Top 1500 Features using ANOVA F-test...\n",
      "\n",
      "📦 Training Voting Classifier with 1500 features...\n",
      "📊 Voting Classifier Metrics:\n",
      "Accuracy: 0.7222222222222222\n",
      "Balanced Accuracy: 0.7222222222222222\n",
      "F1 Score: 0.7368421052631579\n",
      "Precision: 0.7\n",
      "Recall: 0.7777777777777778\n",
      "ROC-AUC: 0.7515432098765432\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "📦 Training Stacking Classifier with 1500 features...\n",
      "📊 Stacking Classifier Metrics:\n",
      "Accuracy: 0.6944444444444444\n",
      "Balanced Accuracy: 0.6944444444444444\n",
      "F1 Score: 0.6944444444444444\n",
      "Precision: 0.6944444444444444\n",
      "Recall: 0.6944444444444444\n",
      "ROC-AUC: 0.7746913580246914\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "🔎 Selecting Top 1400 Features using ANOVA F-test...\n",
      "\n",
      "📦 Training Voting Classifier with 1400 features...\n",
      "📊 Voting Classifier Metrics:\n",
      "Accuracy: 0.6527777777777778\n",
      "Balanced Accuracy: 0.6527777777777777\n",
      "F1 Score: 0.647887323943662\n",
      "Precision: 0.6571428571428571\n",
      "Recall: 0.6388888888888888\n",
      "ROC-AUC: 0.7276234567901234\n",
      "Concordance Index: NA (Error computing with provided survival time)\n",
      "\n",
      "📦 Training Stacking Classifier with 1400 features...\n",
      "📊 Stacking Classifier Metrics:\n",
      "Accuracy: 0.7083333333333334\n",
      "Balanced Accuracy: 0.7083333333333333\n",
      "F1 Score: 0.7123287671232876\n",
      "Precision: 0.7027027027027027\n",
      "Recall: 0.7222222222222222\n",
      "ROC-AUC: 0.7507716049382716\n",
      "Concordance Index: NA (Error computing with provided survival time)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    roc_auc_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Step 1: Load merged data\n",
    "df = pd.read_csv('merged_radiomics_metadata.csv')\n",
    "\n",
    "# Step 2: Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"OS\", \"Survival_Category\"], errors=\"ignore\")\n",
    "if \"1-dead 0-alive\" in df.columns:\n",
    "    y = df[\"1-dead 0-alive\"]\n",
    "else:\n",
    "    raise ValueError(\"Target column '1-dead 0-alive' not found in the dataset.\")\n",
    "\n",
    "# Optional: For Concordance Index\n",
    "survival_times = df[\"OS\"].values if \"OS\" in df.columns else None\n",
    "\n",
    "# Step 3: Encode categorical features\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Step 4: Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Step 5: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Step 6: Apply SMOTE\n",
    "print(\"Class distribution before SMOTE:\\n\", y.value_counts())\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_scaled, y)\n",
    "print(\"Class distribution after SMOTE:\\n\", pd.Series(y_smote).value_counts())\n",
    "\n",
    "# Step 7: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_smote, y_smote, test_size=0.3, stratify=y_smote, random_state=42\n",
    ")\n",
    "\n",
    "# Step 8: Define base models\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
    "svc = SVC(kernel='poly', C=1.0, probability=True, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Step 9: Define ensemble models\n",
    "voting = VotingClassifier(estimators=[\n",
    "    (\"rf\", rf), (\"svc\", svc), (\"logreg\", logreg), (\"lda\", lda)\n",
    "], voting=\"soft\")\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"svc\", svc), (\"logreg\", logreg), (\"lda\", lda)],\n",
    "    final_estimator=LogisticRegression(max_iter=100)\n",
    ")\n",
    "\n",
    "# Step 10: Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_proba=None, survival_time=None):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    if y_proba is not None:\n",
    "        print(\"ROC-AUC:\", roc_auc_score(y_true, y_proba))\n",
    "    if survival_time is not None:\n",
    "        try:\n",
    "            ci = concordance_index(survival_time, -y_proba)\n",
    "            print(\"Concordance Index:\", ci)\n",
    "        except:\n",
    "            print(\"Concordance Index: NA (Error computing with provided survival time)\")\n",
    "\n",
    "# Step 11: Feature reduction and evaluation loop\n",
    "for k in [1693, 1600, 1500, 1400]:\n",
    "    print(f\"\\n🔎 Selecting Top {k} Features using ANOVA F-test...\")\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_k = selector.fit_transform(X_train, y_train)\n",
    "    X_test_k = selector.transform(X_test)\n",
    "\n",
    "    # Voting Classifier\n",
    "    print(f\"\\n📦 Training Voting Classifier with {k} features...\")\n",
    "    voting.fit(X_train_k, y_train)\n",
    "    y_pred_voting = voting.predict(X_test_k)\n",
    "    y_proba_voting = voting.predict_proba(X_test_k)[:, 1]\n",
    "\n",
    "    print(\"📊 Voting Classifier Metrics:\")\n",
    "    evaluate_model(y_test, y_pred_voting, y_proba_voting, survival_time=survival_times)\n",
    "\n",
    "    # Stacking Classifier\n",
    "    print(f\"\\n📦 Training Stacking Classifier with {k} features...\")\n",
    "    stacking.fit(X_train_k, y_train)\n",
    "    y_pred_stacking = stacking.predict(X_test_k)\n",
    "    y_proba_stacking = stacking.predict_proba(X_test_k)[:, 1]\n",
    "\n",
    "    print(\"📊 Stacking Classifier Metrics:\")\n",
    "    evaluate_model(y_test, y_pred_stacking, y_proba_stacking, survival_time=survival_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f180f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      " 1-dead 0-alive\n",
      "1    119\n",
      "0     98\n",
      "Name: count, dtype: int64\n",
      "After SMOTE:\n",
      " 1-dead 0-alive\n",
      "0    119\n",
      "1    119\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🔎 Evaluating Top 1693 Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devyansh\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:776: UserWarning: k=1693 is greater than n_features=1692. All the features will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'Accuracy': 0.9861111111111112, 'Balanced Accuracy': 0.9861111111111112, 'F1': 0.9859154929577465, 'Precision': 1.0, 'Recall': 0.9722222222222222, 'ROC-AUC': 1.0, 'C-Index': None}\n",
      "\n",
      "🔎 Evaluating Top 1650 Features...\n",
      "Metrics: {'Accuracy': 0.625, 'Balanced Accuracy': 0.625, 'F1': 0.6086956521739131, 'Precision': 0.6363636363636364, 'Recall': 0.5833333333333334, 'ROC-AUC': 0.7546296296296297, 'C-Index': None}\n",
      "\n",
      "🔎 Evaluating Top 250 Features...\n",
      "Metrics: {'Accuracy': 0.6805555555555556, 'Balanced Accuracy': 0.6805555555555556, 'F1': 0.676056338028169, 'Precision': 0.6857142857142857, 'Recall': 0.6666666666666666, 'ROC-AUC': 0.7299382716049383, 'C-Index': None}\n",
      "\n",
      "🔎 Evaluating Top 200 Features...\n",
      "Metrics: {'Accuracy': 0.6666666666666666, 'Balanced Accuracy': 0.6666666666666666, 'F1': 0.6756756756756757, 'Precision': 0.6578947368421053, 'Recall': 0.6944444444444444, 'ROC-AUC': 0.7592592592592593, 'C-Index': None}\n",
      "\n",
      "🔎 Evaluating Top 900 Features...\n",
      "Metrics: {'Accuracy': 0.6944444444444444, 'Balanced Accuracy': 0.6944444444444444, 'F1': 0.6857142857142857, 'Precision': 0.7058823529411765, 'Recall': 0.6666666666666666, 'ROC-AUC': 0.7523148148148148, 'C-Index': None}\n",
      "\n",
      "🔎 Evaluating Top 500 Features...\n",
      "Metrics: {'Accuracy': 0.6388888888888888, 'Balanced Accuracy': 0.6388888888888888, 'F1': 0.6285714285714286, 'Precision': 0.6470588235294118, 'Recall': 0.6111111111111112, 'ROC-AUC': 0.7098765432098765, 'C-Index': None}\n",
      "\n",
      "🏆 Best feature count: 1693 with ROC-AUC: 1.0000\n",
      "\n",
      "📊 Final Voting Classifier Metrics:\n",
      "{'Accuracy': 0.9861111111111112, 'Balanced Accuracy': 0.9861111111111112, 'F1': 0.9859154929577465, 'Precision': 1.0, 'Recall': 0.9722222222222222, 'ROC-AUC': 1.0, 'C-Index': None}\n",
      "\n",
      "📊 Final Stacking Classifier Metrics:\n",
      "{'Accuracy': 1.0, 'Balanced Accuracy': 1.0, 'F1': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'ROC-AUC': 1.0, 'C-Index': None}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    roc_auc_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('merged_radiomics_metadata.csv')\n",
    "X = df.drop(columns=[\"OS\", \"Survival_Category\"], errors=\"ignore\")\n",
    "if \"1-dead 0-alive\" in df.columns:\n",
    "    y = df[\"1-dead 0-alive\"]\n",
    "else:\n",
    "    raise ValueError(\"Target column '1-dead 0-alive' not found.\")\n",
    "survival_times = df[\"OS\"].values if \"OS\" in df.columns else None\n",
    "\n",
    "# Encode categoricals\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "for col in categorical_cols:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# Impute & scale\n",
    "X_imputed = SimpleImputer(strategy=\"median\").fit_transform(X)\n",
    "X_scaled = StandardScaler().fit_transform(X_imputed)\n",
    "\n",
    "# SMOTE\n",
    "print(\"Before SMOTE:\\n\", y.value_counts())\n",
    "X_smote, y_smote = SMOTE(random_state=42).fit_resample(X_scaled, y)\n",
    "print(\"After SMOTE:\\n\", pd.Series(y_smote).value_counts())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_smote, y_smote, test_size=0.3, stratify=y_smote, random_state=42\n",
    ")\n",
    "\n",
    "# Base models\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
    "svc = SVC(kernel='poly', C=1.0, probability=True, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Ensembles\n",
    "voting = VotingClassifier(estimators=[\n",
    "    (\"rf\", rf), (\"svc\", svc), (\"logreg\", logreg), (\"lda\", lda)\n",
    "], voting=\"soft\")\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"svc\", svc), (\"logreg\", logreg), (\"lda\", lda)],\n",
    "    final_estimator=LogisticRegression(max_iter=100)\n",
    ")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_proba=None, survival_time=None):\n",
    "    metrics = {}\n",
    "    metrics[\"Accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    metrics[\"Balanced Accuracy\"] = balanced_accuracy_score(y_true, y_pred)\n",
    "    metrics[\"F1\"] = f1_score(y_true, y_pred)\n",
    "    metrics[\"Precision\"] = precision_score(y_true, y_pred)\n",
    "    metrics[\"Recall\"] = recall_score(y_true, y_pred)\n",
    "    if y_proba is not None:\n",
    "        metrics[\"ROC-AUC\"] = roc_auc_score(y_true, y_proba)\n",
    "    if survival_time is not None and y_proba is not None:\n",
    "        try:\n",
    "            metrics[\"C-Index\"] = concordance_index(survival_time, -y_proba)\n",
    "        except:\n",
    "            metrics[\"C-Index\"] = None\n",
    "    return metrics\n",
    "\n",
    "# Feature search loop\n",
    "best_k = None\n",
    "best_auc = 0\n",
    "best_results = {}\n",
    "k_values = [1693, 1650, 250, 200, 900, 500]\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n🔎 Evaluating Top {k} Features...\")\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_k = selector.fit_transform(X_train, y_train)\n",
    "    X_test_k = selector.transform(X_test)\n",
    "\n",
    "    voting.fit(X_train_k, y_train)\n",
    "    y_pred = voting.predict(X_test_k)\n",
    "    y_proba = voting.predict_proba(X_test_k)[:, 1]\n",
    "\n",
    "    results = evaluate_model(y_test, y_pred, y_proba, survival_times)\n",
    "    print(\"Metrics:\", results)\n",
    "\n",
    "    if results.get(\"ROC-AUC\", 0) > best_auc:\n",
    "        best_auc = results[\"ROC-AUC\"]\n",
    "        best_k = k\n",
    "        best_results = results\n",
    "        best_selector = selector  # Store for final use\n",
    "\n",
    "# Final evaluation on best features\n",
    "print(f\"\\n🏆 Best feature count: {best_k} with ROC-AUC: {best_auc:.4f}\")\n",
    "X_train_best = best_selector.transform(X_train)\n",
    "X_test_best = best_selector.transform(X_test)\n",
    "\n",
    "# Re-train both ensembles\n",
    "voting.fit(X_train_best, y_train)\n",
    "stacking.fit(X_train_best, y_train)\n",
    "\n",
    "# Voting Evaluation\n",
    "y_pred_v = voting.predict(X_test_best)\n",
    "y_proba_v = voting.predict_proba(X_test_best)[:, 1]\n",
    "print(\"\\n📊 Final Voting Classifier Metrics:\")\n",
    "final_voting_results = evaluate_model(y_test, y_pred_v, y_proba_v, survival_times)\n",
    "print(final_voting_results)\n",
    "\n",
    "# Stacking Evaluation\n",
    "y_pred_s = stacking.predict(X_test_best)\n",
    "y_proba_s = stacking.predict_proba(X_test_best)[:, 1]\n",
    "print(\"\\n📊 Final Stacking Classifier Metrics:\")\n",
    "final_stacking_results = evaluate_model(y_test, y_pred_s, y_proba_s, survival_times)\n",
    "print(final_stacking_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cda932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
