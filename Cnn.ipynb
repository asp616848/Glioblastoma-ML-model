{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b92bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyradiomics in d:\\mlpr data\\.venv\\lib\\site-packages (3.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.9.2 in d:\\mlpr data\\.venv\\lib\\site-packages (from pyradiomics) (2.2.5)\n",
      "Requirement already satisfied: SimpleITK>=0.9.1 in d:\\mlpr data\\.venv\\lib\\site-packages (from pyradiomics) (2.4.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in d:\\mlpr data\\.venv\\lib\\site-packages (from pyradiomics) (1.8.0)\n",
      "Requirement already satisfied: pykwalify>=1.6.0 in d:\\mlpr data\\.venv\\lib\\site-packages (from pyradiomics) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in d:\\mlpr data\\.venv\\lib\\site-packages (from pyradiomics) (1.17.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in d:\\mlpr data\\.venv\\lib\\site-packages (from pykwalify>=1.6.0->pyradiomics) (0.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in d:\\mlpr data\\.venv\\lib\\site-packages (from pykwalify>=1.6.0->pyradiomics) (2.9.0.post0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16.0 in d:\\mlpr data\\.venv\\lib\\site-packages (from pykwalify>=1.6.0->pyradiomics) (0.18.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in d:\\mlpr data\\.venv\\lib\\site-packages (from ruamel.yaml>=0.16.0->pykwalify>=1.6.0->pyradiomics) (0.2.12)\n"
     ]
    }
   ],
   "source": [
    "pip install pyradiomics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34cbf82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyradiomics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyradiomics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# from pyradiomics import featureextractor\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyradiomics'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import pyradiomics\n",
    "# from pyradiomics import featureextractor\n",
    "import logging\n",
    "\n",
    "# Optional: suppress verbose logging\n",
    "logging.getLogger('radiomics').setLevel(logging.ERROR)\n",
    "\n",
    "# Path to your segmented tumor masks\n",
    "base_dir = r\"C:\\PKG - UPENN-GBM-NIfTI\\UPENN-GBM\\NIfTI-files\\automated_segm\"\n",
    "output_csv = \"tumor_features.csv\"\n",
    "\n",
    "# Configure feature extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "extractor.enableAllFeatures()\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir(base_dir):\n",
    "    if file.endswith('.nii.gz'):\n",
    "        patient_id = file.split('_')[2] if '_' in file else file.split('.')[0]\n",
    "        path = os.path.join(base_dir, file)\n",
    "\n",
    "        # Since it's a binary tumor mask, use the same file as both image and mask\n",
    "        try:\n",
    "            result = extractor.execute(imageFilepath=path, maskFilepath=path)\n",
    "            filtered_result = {k: v for k, v in result.items() if \"diagnostics\" not in k}\n",
    "            filtered_result['PatientID'] = patient_id\n",
    "            data.append(filtered_result)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {file}: {e}\")\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(\"PatientID\", inplace=True)\n",
    "df.to_csv(output_csv)\n",
    "\n",
    "print(f\"Saved {len(df)} feature vectors to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f98fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features extracted and saved to cnn_tumor_features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# ======= 1. CNN Model (Simple 3D CNN as feature extractor) ============\n",
    "class TumorFeatureCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TumorFeatureCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d((4, 4, 4))  # Output shape: (16, 4, 4, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        return x.view(x.size(0), -1)  # Flatten features (batch_size, 1024)\n",
    "\n",
    "# ========= 2. NIfTI loader and preprocessing ===============\n",
    "def load_nifti(path, target_shape=(64, 64, 64)):\n",
    "    data = nib.load(path).get_fdata()\n",
    "    data = (data - data.min()) / (data.max() - data.min() + 1e-6)  # Normalize to [0, 1]\n",
    "    zoom_factors = [t / s for t, s in zip(target_shape, data.shape)]\n",
    "    data = zoom(data, zoom_factors, order=1)  # Resize\n",
    "    data = np.expand_dims(data, axis=0)  # Add channel dim (1, D, H, W)\n",
    "    return torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "# ========== 3. Feature Extraction Pipeline ================\n",
    "def extract_features_from_folder(folder_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TumorFeatureCNN().to(device).eval()\n",
    "\n",
    "    features = []\n",
    "    patient_ids = []\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.endswith('.nii.gz'):\n",
    "            path = os.path.join(folder_path, fname)\n",
    "            # Extract everything before \"_automated_approx_segm.nii.gz\"\n",
    "            patient_id = fname.replace('_automated_approx_segm.nii.gz', '')\n",
    "\n",
    "            try:\n",
    "                tensor = load_nifti(path).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    feat = model(tensor).cpu().numpy().flatten()\n",
    "                features.append(feat)\n",
    "                patient_ids.append(patient_id)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {fname}: {e}\")\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(features)\n",
    "    df.insert(0, \"PatientID\", patient_ids)\n",
    "    return df\n",
    "\n",
    "# ========== 4. Run and Save to CSV ========================\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = r\"C:\\PKG - UPENN-GBM-NIfTI\\UPENN-GBM\\NIfTI-files\\automated_segm\"\n",
    "    output_csv = \"cnn_tumor_features.csv\"\n",
    "\n",
    "    df = extract_features_from_folder(input_folder)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Features extracted and saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810abfa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PatientID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19000\\2963807636.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcnn_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_features_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclinical_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclinical_info_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Merge on patient ID (assuming both columns are named 'ID' in each CSV)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m merged_df = cnn_df.merge(\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mclinical_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Survival_from_surgery_days_UPDATED'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PatientID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m  \u001b[1;31m# keeps all cnn features and fills with NaN if no clinical match\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\mlpr data\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10830\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10832\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\mlpr data\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\mlpr data\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\mlpr data\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\mlpr data\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PatientID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "cnn_features_path = r'D:\\mlpr data\\Glioblastoma-ML-model\\cnn_tumor_features.csv'\n",
    "clinical_info_path = r'D:\\mlpr data\\Glioblastoma-ML-model\\UPENN-GBM_clinical_info_v2.1.csv'\n",
    "output_path = r'D:\\mlpr data\\Glioblastoma-ML-model\\cnn_stacked.csv'\n",
    "\n",
    "# Load data\n",
    "cnn_df = pd.read_csv(cnn_features_path)\n",
    "clinical_df = pd.read_csv(clinical_info_path)\n",
    "\n",
    "# Merge on patient ID (assuming both columns are named 'ID' in each CSV)\n",
    "merged_df = cnn_df.merge(\n",
    "    clinical_df[['ID', 'Survival_from_surgery_days_UPDATED']],\n",
    "    on='ID',\n",
    "    how='left'  # keeps all cnn features and fills with NaN if no clinical match\n",
    ")\n",
    "\n",
    "# Save to output\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"✅ cnn_stacked.csv saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940d814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
