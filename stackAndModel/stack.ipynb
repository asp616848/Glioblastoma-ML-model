{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved at D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# File paths\n",
    "clinical_file = r\"D:\\mlpr data\\Glioblastoma-ML-model\\UPENN-GBM_clinical_info_v2.1.csv\"\n",
    "radiomics_folder = r\"D:\\mlpr data\\radiomic_features_CaPTk\"\n",
    "\n",
    "# Load clinical data\n",
    "clinical_df = pd.read_csv(clinical_file)\n",
    "clinical_df.rename(columns={\"ID\": \"PatientID\"}, inplace=True)  # Standardizing ID column name\n",
    "\n",
    "# Load all radiomic CSVs and merge horizontally on PatientID\n",
    "radiomic_files = glob(os.path.join(radiomics_folder, \"*.csv\"))\n",
    "\n",
    "# Initialize empty dataframe for radiomics\n",
    "radiomics_df = pd.DataFrame()\n",
    "\n",
    "for file in radiomic_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.rename(columns={\"SubjectID\": \"PatientID\"}, inplace=True)  # Standardizing ID column name\n",
    "    \n",
    "    # Merge radiomics files horizontally\n",
    "    if radiomics_df.empty:\n",
    "        radiomics_df = df\n",
    "    else:\n",
    "        radiomics_df = pd.merge(radiomics_df, df, on=\"PatientID\", how=\"outer\")\n",
    "\n",
    "# Merge clinical data with radiomics data\n",
    "merged_df = pd.merge(clinical_df, radiomics_df, on=\"PatientID\", how=\"outer\")\n",
    "\n",
    "# Save final merged dataset\n",
    "output_file = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Merged dataset saved at {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_18804\\2365178571.py:10: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Load data\n",
    "file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert target column to numeric (forcing errors='coerce' turns non-numeric values into NaN)\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\"])  # Drop ID and target\n",
    "y = df[\"Survival_from_surgery_days_UPDATED\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))  # Convert to string before encoding\n",
    "    label_encoders[col] = le  # Store encoder for future use\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\")  # Ensure all values are numeric\n",
    "X = X.fillna(X.median())  # Replace NaNs with median\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 9516)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)  # Use all cores\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 342.39\n",
      "R² Score: 0.0764\n",
      "Root Mean Squared Error (RMSE): 475.31\n",
      "Explained Variance Score: 0.0794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Root Mean Squared Error\n",
    "evs = explained_variance_score(y_test, y_pred)  # Explained Variance Score\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Explained Variance Score: {evs:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_18804\\2159967707.py:10: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43        33\n",
      "           1       0.30      0.19      0.23        32\n",
      "           2       0.24      0.31      0.27        32\n",
      "           3       0.25      0.31      0.28        32\n",
      "\n",
      "    accuracy                           0.30       129\n",
      "   macro avg       0.32      0.30      0.30       129\n",
      "weighted avg       0.32      0.30      0.30       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert target column to numeric (handling non-numeric values)\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "# **Convert Survival Days into Categories (Example Binning)**\n",
    "# You can modify bins as per your requirement\n",
    "percentiles = np.percentile(df[\"Survival_from_surgery_days_UPDATED\"], [25,50, 75])  \n",
    "bins = [0, percentiles[0], percentiles[1], percentiles[2], np.inf]  \n",
    "labels = [0, 1, 2, 3]  # Adjust as needed\n",
    "df[\"Survival_Category\"] = pd.cut(df[\"Survival_from_surgery_days_UPDATED\"], bins=bins, labels=labels)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "y = df[\"Survival_Category\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))  # Convert to string before encoding\n",
    "    label_encoders[col] = le  # Store encoders for future use\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\")  # Ensure all values are numeric\n",
    "X = X.fillna(X.median())  # Replace NaNs with median\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_18804\\571684290.py:11: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.42      0.41        33\n",
      "           1       0.31      0.25      0.28        32\n",
      "           2       0.29      0.28      0.29        32\n",
      "           3       0.28      0.31      0.29        32\n",
      "\n",
      "    accuracy                           0.32       129\n",
      "   macro avg       0.32      0.32      0.32       129\n",
      "weighted avg       0.32      0.32      0.32       129\n",
      "\n",
      "Number of PCA components used: 182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert target column to numeric (handling non-numeric values)\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "percentiles = np.percentile(df[\"Survival_from_surgery_days_UPDATED\"], [25,50, 75])  \n",
    "bins = [0, percentiles[0], percentiles[1], percentiles[2], np.inf]  \n",
    "labels = [0, 1, 2, 3]  # Adjust as needed\n",
    "df[\"Survival_Category\"] = pd.cut(df[\"Survival_from_surgery_days_UPDATED\"], bins=bins, labels=labels)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "y = df[\"Survival_Category\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))  # Convert to string before encoding\n",
    "    label_encoders[col] = le  # Store encoders for future use\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\")  # Ensure all values are numeric\n",
    "X = X.fillna(X.median())  # Replace NaNs with median\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.9)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Train-test split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Print the number of PCA components\n",
    "print(f\"Number of PCA components used: {X_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_19192\\3966034821.py:15: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.53\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55        43\n",
      "           1       0.40      0.33      0.36        42\n",
      "           2       0.67      0.64      0.65        44\n",
      "\n",
      "    accuracy                           0.53       129\n",
      "   macro avg       0.52      0.52      0.52       129\n",
      "weighted avg       0.52      0.53      0.52       129\n",
      "\n",
      "Stacking Model Accuracy: 0.44\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.51        43\n",
      "           1       0.36      0.36      0.36        42\n",
      "           2       0.49      0.43      0.46        44\n",
      "\n",
      "    accuracy                           0.44       129\n",
      "   macro avg       0.44      0.44      0.44       129\n",
      "weighted avg       0.44      0.44      0.44       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert target column to numeric\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "# Percentile-Based Binning\n",
    "percentiles = np.percentile(df[\"Survival_from_surgery_days_UPDATED\"], [33, 66])\n",
    "bins = [0, percentiles[0], percentiles[1], np.inf]\n",
    "labels = [0, 1, 2]  \n",
    "\n",
    "df[\"Survival_Category\"] = pd.cut(df[\"Survival_from_surgery_days_UPDATED\"], bins=bins, labels=labels)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "y = df[\"Survival_Category\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(X.median())\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature Selection using RandomForest\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=150, random_state=42), max_features=100)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# Train-test split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Balance Classes with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define Base Models\n",
    "rf_clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Voting Classifier (Soft Voting for Probabilistic Averaging)\n",
    "ensemble_model_1 = VotingClassifier(\n",
    "    estimators=[(\"RandomForest\", rf_clf), (\"XGBoost\", xgb_clf), (\"LogReg\", log_reg)],\n",
    "    voting=\"soft\"  # Example of weight assignment\n",
    ")\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[(\"RandomForest\", rf_clf), (\"XGBoost\", xgb_clf), (\"LogReg\", log_reg)],\n",
    "    final_estimator=RandomForestClassifier()\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train Ensemble Model\n",
    "ensemble_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = ensemble_model_1.predict(X_test)\n",
    "y_pred_stacking = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "report = classification_report(y_test, y_pred)\n",
    "report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy_stacking:.2f}\")\n",
    "print(\"Classification Report:\\n\", report_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_18804\\3205822300.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles for Binning: [234.   506.52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [   2    3   69   74   80  103  104  105  107  108  110  213  218  224\n",
      "  247  248  249  251  252  254  357  362  368  391  392  393  501  506\n",
      "  512  535  536  537  539  540  542  645  650  656  679  680  681  683\n",
      "  684  686  789  794  800  823  824  825  933  938  944  967  968  969\n",
      "  971  972  974 1077 1082 1088 1111 1112 1113 1115 1116 1118 1221 1226\n",
      " 1232 1255 1256 1257 1365 1370 1376 1399 1400 1401 1403 1404 1406 1509\n",
      " 1514 1520 1543 1544 1545 1547 1548 1550 1653 1658 1664 1687 1688 1689\n",
      " 1797 1802 1808 1831 1832 1833 1835 1836 1838 1941 1946 1952 1975 1976\n",
      " 1977 1979 1980 1982 2085 2090 2096 2119 2120 2121 2229 2234 2240 2263\n",
      " 2264 2265 2267 2268 2270 2373 2378 2384 2407 2408 2409 2411 2412 2414\n",
      " 2517 2522 2528 2551 2552 2553 2661 2666 2672 2695 2696 2697 2699 2700\n",
      " 2702 2805 2810 2816 2839 2840 2841 2843 2844 2846 2949 2954 2960 2983\n",
      " 2984 2985 3093 3098 3104 3127 3128 3129 3237 3242 3248 3271 3272 3273\n",
      " 3275 3276 3278 3381 3386 3392 3415 3416 3417 3525 3530 3536 3559 3560\n",
      " 3561 3669 3674 3680 3703 3704 3705 3707 3708 3710 3813 3818 3824 3847\n",
      " 3848 3849 3957 3962 3968 3991 3992 3993 4101 4106 4112 4135 4136 4137\n",
      " 4139 4140 4142 4245 4250 4256 4279 4280 4281 4389 4394 4400 4423 4424\n",
      " 4425 4533 4538 4544 4567 4568 4569 4571 4572 4574 4677 4682 4688 4711\n",
      " 4712 4713 4821 4826 4832 4855 4856 4857 4859 4860 4862 4965 4970 4976\n",
      " 4999 5000 5001 5003 5004 5006 5109 5114 5120 5143 5144 5145 5147 5148\n",
      " 5150 5253 5258 5264 5287 5288 5289 5291 5292 5294 5397 5402 5408 5431\n",
      " 5432 5433 5435 5436 5438 5541 5546 5552 5575 5576 5577 5579 5580 5582\n",
      " 5685 5690 5696 5719 5720 5721 5723 5724 5726 5829 5834 5840 5863 5864\n",
      " 5865 5867 5868 5870 5973 5978 5984 6007 6008 6009 6011 6012 6014 6117\n",
      " 6122 6128 6151 6152 6153 6155 6156 6158 6261 6266 6272 6295 6296 6297\n",
      " 6299 6300 6302 6405 6410 6416 6439 6440 6441 6443 6444 6446 6549 6554\n",
      " 6560 6583 6584 6585 6587 6588 6590 6693 6698 6704 6727 6728 6729 6731\n",
      " 6732 6734 6837 6842 6848 6871 6872 6873 6875 6876 6878 6981 6986 6992\n",
      " 7015 7016 7017 7019 7020 7022 7125 7130 7136 7159 7160 7161 7163 7164\n",
      " 7166 7269 7274 7280 7303 7304 7305 7307 7308 7310 7413 7418 7424 7447\n",
      " 7448 7449 7451 7452 7454 7557 7562 7568 7591 7592 7593 7595 7596 7598\n",
      " 7701 7706 7712 7735 7736 7737 7739 7740 7742 7845 7850 7856 7879 7880\n",
      " 7881 7883 7884 7886 7989 7994 8000 8023 8024 8025 8027 8028 8030 8133\n",
      " 8138 8144 8167 8168 8169 8171 8172 8174 8277 8282 8288 8311 8312 8313\n",
      " 8315 8316 8318 8421 8426 8432 8455 8456 8457 8459 8460 8462 8565 8570\n",
      " 8576 8599 8600 8601 8603 8604 8606 8709 8714 8720 8743 8744 8745 8747\n",
      " 8748 8750 8853 8858 8864 8887 8888 8889 8891 8892 8894 8997 9002 9008\n",
      " 9031 9032 9033 9035 9036 9038 9141 9146 9152 9175 9176 9177 9179 9180\n",
      " 9182 9285 9290 9296 9319 9320 9321 9323 9324 9326 9429 9434 9440 9463\n",
      " 9464 9465 9467 9468 9470] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[31  7  5]\n",
      " [18  6 18]\n",
      " [ 5 11 28]]\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.64        43\n",
      "           1       0.25      0.14      0.18        42\n",
      "           2       0.55      0.64      0.59        44\n",
      "\n",
      "    accuracy                           0.50       129\n",
      "   macro avg       0.46      0.50      0.47       129\n",
      "weighted avg       0.46      0.50      0.47       129\n",
      "\n",
      "\n",
      "Cross-Validation Scores: [0.46666667 0.4952381  0.48571429 0.4952381  0.53333333]\n",
      "Mean CV Score: 0.49523809523809526\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "\n",
    "class AdvancedEnsembleClassifier:\n",
    "    def __init__(self, file_path):\n",
    "        # Load data\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.prepare_data()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # Convert target column to numeric\n",
    "        self.df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(\n",
    "            self.df[\"Survival_from_surgery_days_UPDATED\"], \n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "        # Drop rows where target variable is NaN\n",
    "        self.df = self.df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "        # Percentile-Based Binning with adjustment\n",
    "        percentiles = np.percentile(self.df[\"Survival_from_surgery_days_UPDATED\"], [33,66])\n",
    "        bins = [0, percentiles[0], percentiles[1], np.inf]\n",
    "        print(\"Percentiles for Binning:\", percentiles)\n",
    "        labels = [0, 1, 2]  \n",
    "\n",
    "        self.df[\"Survival_Category\"] = pd.cut(\n",
    "            self.df[\"Survival_from_surgery_days_UPDATED\"], \n",
    "            bins=bins, \n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = self.df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "        y = self.df[\"Survival_Category\"].astype(int)\n",
    "\n",
    "        # Encode categorical columns\n",
    "        categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "        self.label_encoders = {}\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "\n",
    "        # Fill missing numeric values with median\n",
    "        X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(X.median())\n",
    "\n",
    "        # Standardize numeric features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "\n",
    "        # Feature Selection\n",
    "        self.selector = SelectKBest(score_func=f_classif, k=50)\n",
    "        X_selected = self.selector.fit_transform(X_scaled, y)\n",
    "\n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X_selected, y, \n",
    "            test_size=0.2, \n",
    "            random_state=42, \n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "        # Apply SMOTE for class balancing\n",
    "        smote = SMOTE(random_state=42)\n",
    "        self.X_train, self.y_train = smote.fit_resample(self.X_train, self.y_train)\n",
    "    \n",
    "    def create_models(self):\n",
    "        # Base models with improved parameters\n",
    "        rf_clf = RandomForestClassifier(\n",
    "            n_estimators=300, \n",
    "            max_depth=10, \n",
    "            min_samples_split=5, \n",
    "            min_samples_leaf=2, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        xgb_clf = xgb.XGBClassifier(\n",
    "            n_estimators=250, \n",
    "            learning_rate=0.05, \n",
    "            max_depth=40, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        svm_clf = SVC(\n",
    "            kernel='rbf', \n",
    "            probability=True, \n",
    "            C=1.0, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Stacking Classifier with multiple base models\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', rf_clf),\n",
    "                ('xgb', xgb_clf),\n",
    "                ('svm', svm_clf)\n",
    "            ],\n",
    "            final_estimator=LogisticRegression(max_iter=1000),\n",
    "            cv=5\n",
    "        )\n",
    "        \n",
    "        return stacking_clf\n",
    "    \n",
    "    def train_and_evaluate(self):\n",
    "        # Create and train the model\n",
    "        model = self.create_models()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        \n",
    "        # Detailed evaluation\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(self.y_test, y_pred))\n",
    "        \n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, self.X_train, self.y_train, cv=5)\n",
    "        print(\"\\nCross-Validation Scores:\", cv_scores)\n",
    "        print(\"Mean CV Score:\", cv_scores.mean())\n",
    "        \n",
    "        return model\n",
    "\n",
    "def main():\n",
    "    file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "    ensemble = AdvancedEnsembleClassifier(file_path)\n",
    "    model = ensemble.train_and_evaluate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_19192\\770886090.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:34:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:34:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:35:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble (Voting) Accuracy: 0.54\n",
      "Voting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.63      0.56        43\n",
      "           1       0.43      0.36      0.39        42\n",
      "           2       0.70      0.64      0.67        44\n",
      "\n",
      "    accuracy                           0.54       129\n",
      "   macro avg       0.54      0.54      0.54       129\n",
      "weighted avg       0.54      0.54      0.54       129\n",
      "\n",
      "\n",
      "Stacking Accuracy: 0.48\n",
      "Stacking Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.58      0.55        43\n",
      "           1       0.36      0.31      0.33        42\n",
      "           2       0.53      0.55      0.54        44\n",
      "\n",
      "    accuracy                           0.48       129\n",
      "   macro avg       0.47      0.48      0.47       129\n",
      "weighted avg       0.47      0.48      0.48       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Target processing\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "# Binning the target\n",
    "percentiles = np.percentile(df[\"Survival_from_surgery_days_UPDATED\"], [33, 66])\n",
    "bins = [0, percentiles[0], percentiles[1], np.inf]\n",
    "labels = [0, 1, 2]\n",
    "df[\"Survival_Category\"] = pd.cut(df[\"Survival_from_surgery_days_UPDATED\"], bins=bins, labels=labels)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "y = df[\"Survival_Category\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Fill and scale\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(X.median())\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=150, random_state=42), max_features=100)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# Split and balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42, stratify=y)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define base models\n",
    "rf_clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "svm_clf = SVC(probability=True, kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
    "\n",
    "# Voting Classifier (soft voting)\n",
    "ensemble_model_2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomForest\", rf_clf),\n",
    "        (\"XGBoost\", xgb_clf),\n",
    "        (\"LogReg\", log_reg),\n",
    "        (\"SVM\", svm_clf)\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf_2 = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomForest\", rf_clf),\n",
    "        (\"XGBoost\", xgb_clf),\n",
    "        (\"LogReg\", log_reg),\n",
    "        (\"SVM\", svm_clf)\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42)\n",
    ")\n",
    "\n",
    "# Train models\n",
    "ensemble_model_2.fit(X_train, y_train)\n",
    "stacking_clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "y_pred = ensemble_model_2.predict(X_test)\n",
    "y_pred_stacking = stacking_clf_2.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "print(f\"\\nEnsemble (Voting) Accuracy: {accuracy:.2f}\")\n",
    "print(\"Voting Classification Report:\\n\", report)\n",
    "\n",
    "print(f\"\\nStacking Accuracy: {accuracy_stacking:.2f}\")\n",
    "print(\"Stacking Classification Report:\\n\", report_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asp61\\AppData\\Local\\Temp\\ipykernel_19192\\2758369117.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.57\n",
      "Classification Report (Ensemble):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59        43\n",
      "           1       0.57      0.31      0.40        42\n",
      "           2       0.66      0.66      0.66        44\n",
      "\n",
      "    accuracy                           0.57       129\n",
      "   macro avg       0.57      0.56      0.55       129\n",
      "weighted avg       0.58      0.57      0.55       129\n",
      "\n",
      "Stacking Model Accuracy: 0.44\n",
      "Classification Report (Stacking):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.63      0.53        43\n",
      "           1       0.31      0.29      0.30        42\n",
      "           2       0.58      0.41      0.48        44\n",
      "\n",
      "    accuracy                           0.44       129\n",
      "   macro avg       0.45      0.44      0.44       129\n",
      "weighted avg       0.45      0.44      0.44       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "# Replace with your actual file path\n",
    "file_path =  r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert target column to numeric\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "# Percentile-Based Binning - fixed the bins issue\n",
    "percentiles = np.percentile(df[\"Survival_from_surgery_days_UPDATED\"], [33, 66])\n",
    "bins = [0, percentiles[0], percentiles[1], np.inf]  # Corrected bins definition\n",
    "labels = [0, 1, 2]  \n",
    "\n",
    "df[\"Survival_Category\"] = pd.cut(df[\"Survival_from_surgery_days_UPDATED\"], bins=bins, labels=labels)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "y = df[\"Survival_Category\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(X.median())\n",
    "\n",
    "# Train-test split (80:20) - Do this before scaling to prevent data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a preprocessing pipeline with scaling and feature selection\n",
    "preprocessor = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selector', SelectFromModel(\n",
    "        GradientBoostingClassifier(n_estimators=100, random_state=42), \n",
    "        max_features=50)  # Reduced from 100 to 50 features\n",
    "    )\n",
    "])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE for class balancing\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)  # Specify k_neighbors for better results\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# Define Base Models with tuned hyperparameters\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=150, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=5, \n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    C=0.5,\n",
    "    solver='liblinear',\n",
    "    max_iter=2000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "knn_clf = KNeighborsClassifier(\n",
    "    n_neighbors=7,\n",
    "    weights='distance'\n",
    ")\n",
    "\n",
    "svm_clf = SVC(\n",
    "    C=1.0,\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Voting Classifier with adjusted weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomForest\", rf_clf), \n",
    "        (\"XGBoost\", xgb_clf), \n",
    "        (\"LogReg\", log_reg),\n",
    "        (\"KNN\", knn_clf),\n",
    "        (\"SVM\", svm_clf)\n",
    "    ],\n",
    "    voting=\"soft\", \n",
    "    weights=[2, 2, 1, 1, 1.5]  # Adjusted weights\n",
    ")\n",
    "\n",
    "# Stacking Classifier with a different meta-learner\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomForest\", rf_clf), \n",
    "        (\"XGBoost\", xgb_clf), \n",
    "        (\"LogReg\", log_reg),\n",
    "        (\"KNN\", knn_clf)\n",
    "    ],\n",
    "    final_estimator=GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    cv=5  # 5-fold cross-validation\n",
    ")\n",
    "\n",
    "# Train models\n",
    "ensemble_model.fit(X_train_resampled, y_train_resampled)\n",
    "stacking_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_processed)\n",
    "y_pred_stacking = stacking_clf.predict(X_test_processed)\n",
    "\n",
    "# Evaluate models\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble:.2f}\")\n",
    "print(\"Classification Report (Ensemble):\\n\", classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "print(f\"Stacking Model Accuracy: {accuracy_stacking:.2f}\")\n",
    "print(\"Classification Report (Stacking):\\n\", classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asp61\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-09 13:42:42,025] A new study created in memory with name: no-name-db42d963-5cb5-437f-b4d4-c1dab7ff1308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Ensemble Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 13:42:43,621] Trial 0 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 195, 'rf_max_depth': 9, 'rf_min_samples_split': 3, 'xgb_n_estimators': 81, 'xgb_learning_rate': 0.012624668075432121, 'xgb_max_depth': 10, 'xgb_subsample': 0.943592368284729, 'xgb_colsample_bytree': 0.8578348706209307, 'log_reg_C': 0.03392751113421898, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:45,176] Trial 1 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 280, 'rf_max_depth': 12, 'rf_min_samples_split': 14, 'xgb_n_estimators': 83, 'xgb_learning_rate': 0.10716866082486512, 'xgb_max_depth': 4, 'xgb_subsample': 0.6476011172100687, 'xgb_colsample_bytree': 0.8064298718394076, 'log_reg_C': 0.5350465072659588, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:45,995] Trial 2 finished with value: 0.9446291615207899 and parameters: {'rf_n_estimators': 55, 'rf_max_depth': 11, 'rf_min_samples_split': 4, 'xgb_n_estimators': 120, 'xgb_learning_rate': 0.05799137436036437, 'xgb_max_depth': 9, 'xgb_subsample': 0.7652222039142667, 'xgb_colsample_bytree': 0.8447215728292252, 'log_reg_C': 7.393795312643763, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:47,846] Trial 3 finished with value: 0.9465391149758562 and parameters: {'rf_n_estimators': 210, 'rf_max_depth': 13, 'rf_min_samples_split': 4, 'xgb_n_estimators': 217, 'xgb_learning_rate': 0.08086181210227616, 'xgb_max_depth': 5, 'xgb_subsample': 0.7322799012505111, 'xgb_colsample_bytree': 0.662655113151194, 'log_reg_C': 0.31983305864468126, 'log_reg_solver': 'liblinear'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:49,434] Trial 4 finished with value: 0.9465391149758562 and parameters: {'rf_n_estimators': 198, 'rf_max_depth': 20, 'rf_min_samples_split': 9, 'xgb_n_estimators': 163, 'xgb_learning_rate': 0.05787150953759566, 'xgb_max_depth': 4, 'xgb_subsample': 0.8282501923738756, 'xgb_colsample_bytree': 0.8961939893517705, 'log_reg_C': 0.9275820900215785, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:50,726] Trial 5 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 200, 'rf_max_depth': 14, 'rf_min_samples_split': 16, 'xgb_n_estimators': 69, 'xgb_learning_rate': 0.16750990892579276, 'xgb_max_depth': 3, 'xgb_subsample': 0.62115453400898, 'xgb_colsample_bytree': 0.8198739585563658, 'log_reg_C': 0.0138975372596006, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:53,365] Trial 6 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 147, 'rf_max_depth': 15, 'rf_min_samples_split': 7, 'xgb_n_estimators': 281, 'xgb_learning_rate': 0.015305775134469667, 'xgb_max_depth': 8, 'xgb_subsample': 0.9562379330375597, 'xgb_colsample_bytree': 0.9475638967609769, 'log_reg_C': 1.5911133029769813, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:54,535] Trial 7 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 80, 'rf_max_depth': 3, 'rf_min_samples_split': 19, 'xgb_n_estimators': 162, 'xgb_learning_rate': 0.07298859056335374, 'xgb_max_depth': 5, 'xgb_subsample': 0.8035613021081957, 'xgb_colsample_bytree': 0.864934111056351, 'log_reg_C': 0.5664748670271927, 'log_reg_solver': 'saga'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:55,779] Trial 8 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 173, 'rf_max_depth': 20, 'rf_min_samples_split': 6, 'xgb_n_estimators': 98, 'xgb_learning_rate': 0.01901543788711685, 'xgb_max_depth': 4, 'xgb_subsample': 0.6420656226572136, 'xgb_colsample_bytree': 0.786202463516002, 'log_reg_C': 1.0728820598986735, 'log_reg_solver': 'lbfgs'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:57,616] Trial 9 finished with value: 0.9465391149758562 and parameters: {'rf_n_estimators': 248, 'rf_max_depth': 4, 'rf_min_samples_split': 15, 'xgb_n_estimators': 127, 'xgb_learning_rate': 0.18301557366004337, 'xgb_max_depth': 8, 'xgb_subsample': 0.9807666123160839, 'xgb_colsample_bytree': 0.6857565464994042, 'log_reg_C': 9.155894698786637, 'log_reg_solver': 'saga'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:42:59,900] Trial 10 finished with value: 0.9523411563829395 and parameters: {'rf_n_estimators': 127, 'rf_max_depth': 8, 'rf_min_samples_split': 2, 'xgb_n_estimators': 214, 'xgb_learning_rate': 0.028151271896630414, 'xgb_max_depth': 10, 'xgb_subsample': 0.8966175655853781, 'xgb_colsample_bytree': 0.9807881540825996, 'log_reg_C': 0.0313008174315488, 'log_reg_solver': 'liblinear'}. Best is trial 0 with value: 0.9524198078256308.\n",
      "[I 2025-04-09 13:43:02,254] Trial 11 finished with value: 0.9542609835857856 and parameters: {'rf_n_estimators': 124, 'rf_max_depth': 8, 'rf_min_samples_split': 2, 'xgb_n_estimators': 227, 'xgb_learning_rate': 0.02411785491398546, 'xgb_max_depth': 10, 'xgb_subsample': 0.9173229807998943, 'xgb_colsample_bytree': 0.9809914380784289, 'log_reg_C': 0.03053110065048662, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:04,425] Trial 12 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 121, 'rf_max_depth': 7, 'rf_min_samples_split': 2, 'xgb_n_estimators': 267, 'xgb_learning_rate': 0.01013816763964868, 'xgb_max_depth': 10, 'xgb_subsample': 0.8966441531392955, 'xgb_colsample_bytree': 0.9149215088077152, 'log_reg_C': 0.06942693041135774, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:06,511] Trial 13 finished with value: 0.9524029599963523 and parameters: {'rf_n_estimators': 97, 'rf_max_depth': 8, 'rf_min_samples_split': 11, 'xgb_n_estimators': 226, 'xgb_learning_rate': 0.03004666582936152, 'xgb_max_depth': 7, 'xgb_subsample': 0.9055530850714131, 'xgb_colsample_bytree': 0.7311873297326864, 'log_reg_C': 0.08675651931194345, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:08,816] Trial 14 finished with value: 0.9504435986030287 and parameters: {'rf_n_estimators': 163, 'rf_max_depth': 6, 'rf_min_samples_split': 7, 'xgb_n_estimators': 247, 'xgb_learning_rate': 0.03205684161302235, 'xgb_max_depth': 9, 'xgb_subsample': 0.9442606163430739, 'xgb_colsample_bytree': 0.9908739125648346, 'log_reg_C': 0.011135162025314633, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:11,212] Trial 15 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 260, 'rf_max_depth': 10, 'rf_min_samples_split': 11, 'xgb_n_estimators': 186, 'xgb_learning_rate': 0.011094804751378973, 'xgb_max_depth': 10, 'xgb_subsample': 0.8519327877316499, 'xgb_colsample_bytree': 0.7540261442222993, 'log_reg_C': 0.09829127028607382, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:12,618] Trial 16 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 230, 'rf_max_depth': 10, 'rf_min_samples_split': 4, 'xgb_n_estimators': 53, 'xgb_learning_rate': 0.01903213914249853, 'xgb_max_depth': 7, 'xgb_subsample': 0.8651748023784277, 'xgb_colsample_bytree': 0.9231656000503373, 'log_reg_C': 0.03400154301610198, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:14,474] Trial 17 finished with value: 0.9504604464323073 and parameters: {'rf_n_estimators': 141, 'rf_max_depth': 5, 'rf_min_samples_split': 2, 'xgb_n_estimators': 134, 'xgb_learning_rate': 0.03750420371883635, 'xgb_max_depth': 9, 'xgb_subsample': 0.9995338107422203, 'xgb_colsample_bytree': 0.6243782233325947, 'log_reg_C': 0.1597062365101021, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:17,621] Trial 18 finished with value: 0.9504435986030287 and parameters: {'rf_n_estimators': 101, 'rf_max_depth': 9, 'rf_min_samples_split': 5, 'xgb_n_estimators': 299, 'xgb_learning_rate': 0.016097443088549768, 'xgb_max_depth': 8, 'xgb_subsample': 0.9343102990982347, 'xgb_colsample_bytree': 0.8719573929818037, 'log_reg_C': 0.029198791003168106, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:20,051] Trial 19 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 187, 'rf_max_depth': 16, 'rf_min_samples_split': 9, 'xgb_n_estimators': 181, 'xgb_learning_rate': 0.023520139070476266, 'xgb_max_depth': 6, 'xgb_subsample': 0.7461024250118421, 'xgb_colsample_bytree': 0.9598118985811714, 'log_reg_C': 0.18944739488631873, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:22,013] Trial 20 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 57, 'rf_max_depth': 18, 'rf_min_samples_split': 9, 'xgb_n_estimators': 198, 'xgb_learning_rate': 0.0135358647797468, 'xgb_max_depth': 9, 'xgb_subsample': 0.9219188730917791, 'xgb_colsample_bytree': 0.7605896983514627, 'log_reg_C': 0.021036894457096313, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:24,999] Trial 21 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 123, 'rf_max_depth': 7, 'rf_min_samples_split': 2, 'xgb_n_estimators': 256, 'xgb_learning_rate': 0.010867550512013213, 'xgb_max_depth': 10, 'xgb_subsample': 0.876770600489498, 'xgb_colsample_bytree': 0.8999668995355191, 'log_reg_C': 0.060713018694029855, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:28,466] Trial 22 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 115, 'rf_max_depth': 6, 'rf_min_samples_split': 2, 'xgb_n_estimators': 263, 'xgb_learning_rate': 0.011057188761996791, 'xgb_max_depth': 10, 'xgb_subsample': 0.9628980086235172, 'xgb_colsample_bytree': 0.9391551255576814, 'log_reg_C': 0.058430017599614435, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:31,270] Trial 23 finished with value: 0.9523411563829395 and parameters: {'rf_n_estimators': 157, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'xgb_n_estimators': 237, 'xgb_learning_rate': 0.03934143308782352, 'xgb_max_depth': 10, 'xgb_subsample': 0.8333107281147506, 'xgb_colsample_bytree': 0.9111231839447318, 'log_reg_C': 0.047095901133404595, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:34,716] Trial 24 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 226, 'rf_max_depth': 10, 'rf_min_samples_split': 6, 'xgb_n_estimators': 273, 'xgb_learning_rate': 0.021566828396496308, 'xgb_max_depth': 9, 'xgb_subsample': 0.9038310924946438, 'xgb_colsample_bytree': 0.8537192763697432, 'log_reg_C': 0.01795976252247712, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:37,947] Trial 25 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 135, 'rf_max_depth': 6, 'rf_min_samples_split': 3, 'xgb_n_estimators': 288, 'xgb_learning_rate': 0.014113785537740274, 'xgb_max_depth': 8, 'xgb_subsample': 0.999027275263951, 'xgb_colsample_bytree': 0.9716445624277076, 'log_reg_C': 0.1369376507679683, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:40,192] Trial 26 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 86, 'rf_max_depth': 12, 'rf_min_samples_split': 6, 'xgb_n_estimators': 206, 'xgb_learning_rate': 0.010537521690271912, 'xgb_max_depth': 10, 'xgb_subsample': 0.8784002199339324, 'xgb_colsample_bytree': 0.8860602300060623, 'log_reg_C': 0.2635943726617407, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:43,473] Trial 27 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 173, 'rf_max_depth': 4, 'rf_min_samples_split': 13, 'xgb_n_estimators': 235, 'xgb_learning_rate': 0.27319729903389156, 'xgb_max_depth': 9, 'xgb_subsample': 0.6968129312252527, 'xgb_colsample_bytree': 0.9981733215211824, 'log_reg_C': 0.08249136248437469, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:48,165] Trial 28 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 108, 'rf_max_depth': 9, 'rf_min_samples_split': 19, 'xgb_n_estimators': 149, 'xgb_learning_rate': 0.024363272887366748, 'xgb_max_depth': 7, 'xgb_subsample': 0.8033455840249987, 'xgb_colsample_bytree': 0.8301016659355956, 'log_reg_C': 0.022695310338980836, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:43:53,378] Trial 29 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 295, 'rf_max_depth': 11, 'rf_min_samples_split': 8, 'xgb_n_estimators': 104, 'xgb_learning_rate': 0.04576537997508525, 'xgb_max_depth': 10, 'xgb_subsample': 0.9290726030250915, 'xgb_colsample_bytree': 0.9428371337476629, 'log_reg_C': 0.010033911021883649, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:01,442] Trial 30 finished with value: 0.9504604464323073 and parameters: {'rf_n_estimators': 76, 'rf_max_depth': 7, 'rf_min_samples_split': 3, 'xgb_n_estimators': 262, 'xgb_learning_rate': 0.016817202158583625, 'xgb_max_depth': 6, 'xgb_subsample': 0.9683569610921443, 'xgb_colsample_bytree': 0.9235819517227689, 'log_reg_C': 0.04535627990438538, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:06,137] Trial 31 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 265, 'rf_max_depth': 10, 'rf_min_samples_split': 11, 'xgb_n_estimators': 186, 'xgb_learning_rate': 0.012485836526706533, 'xgb_max_depth': 10, 'xgb_subsample': 0.8510633492967763, 'xgb_colsample_bytree': 0.7860193370856366, 'log_reg_C': 0.10348971959574087, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:08,684] Trial 32 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 248, 'rf_max_depth': 9, 'rf_min_samples_split': 17, 'xgb_n_estimators': 196, 'xgb_learning_rate': 0.010351826557172625, 'xgb_max_depth': 9, 'xgb_subsample': 0.8454399507043375, 'xgb_colsample_bytree': 0.73300083607086, 'log_reg_C': 0.07598403056072549, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:11,614] Trial 33 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 277, 'rf_max_depth': 13, 'rf_min_samples_split': 13, 'xgb_n_estimators': 220, 'xgb_learning_rate': 0.013845498322783072, 'xgb_max_depth': 10, 'xgb_subsample': 0.8901773920882302, 'xgb_colsample_bytree': 0.7516111504652667, 'log_reg_C': 0.12016252367451073, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:13,723] Trial 34 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 218, 'rf_max_depth': 11, 'rf_min_samples_split': 3, 'xgb_n_estimators': 157, 'xgb_learning_rate': 0.02007304836584599, 'xgb_max_depth': 9, 'xgb_subsample': 0.7661110767906222, 'xgb_colsample_bytree': 0.8086609195709527, 'log_reg_C': 0.24977289990704563, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:15,941] Trial 35 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 191, 'rf_max_depth': 12, 'rf_min_samples_split': 5, 'xgb_n_estimators': 174, 'xgb_learning_rate': 0.012414125026704836, 'xgb_max_depth': 10, 'xgb_subsample': 0.8212388773598277, 'xgb_colsample_bytree': 0.8465029411977301, 'log_reg_C': 0.035231050959016644, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:20,275] Trial 36 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 300, 'rf_max_depth': 7, 'rf_min_samples_split': 5, 'xgb_n_estimators': 247, 'xgb_learning_rate': 0.016792997291640677, 'xgb_max_depth': 8, 'xgb_subsample': 0.9248512284202646, 'xgb_colsample_bytree': 0.6865612432069057, 'log_reg_C': 4.864295119486604, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:21,961] Trial 37 finished with value: 0.9465391149758562 and parameters: {'rf_n_estimators': 157, 'rf_max_depth': 13, 'rf_min_samples_split': 11, 'xgb_n_estimators': 145, 'xgb_learning_rate': 0.11034482495461768, 'xgb_max_depth': 3, 'xgb_subsample': 0.8605415567077819, 'xgb_colsample_bytree': 0.8325659299154895, 'log_reg_C': 0.5394123907431289, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:23,615] Trial 38 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 241, 'rf_max_depth': 5, 'rf_min_samples_split': 3, 'xgb_n_estimators': 75, 'xgb_learning_rate': 0.010135029406501295, 'xgb_max_depth': 9, 'xgb_subsample': 0.7838150647125514, 'xgb_colsample_bytree': 0.8794878937943325, 'log_reg_C': 0.016691197422952313, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:25,429] Trial 39 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 265, 'rf_max_depth': 9, 'rf_min_samples_split': 20, 'xgb_n_estimators': 92, 'xgb_learning_rate': 0.02563176713292319, 'xgb_max_depth': 10, 'xgb_subsample': 0.7065488155399763, 'xgb_colsample_bytree': 0.9567632475372819, 'log_reg_C': 0.04421145611428081, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:28,177] Trial 40 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 210, 'rf_max_depth': 10, 'rf_min_samples_split': 17, 'xgb_n_estimators': 229, 'xgb_learning_rate': 0.01746906875966048, 'xgb_max_depth': 8, 'xgb_subsample': 0.9084140925441205, 'xgb_colsample_bytree': 0.7874240749588107, 'log_reg_C': 0.3809930439737176, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:29,494] Trial 41 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 235, 'rf_max_depth': 11, 'rf_min_samples_split': 4, 'xgb_n_estimators': 50, 'xgb_learning_rate': 0.020455260576059866, 'xgb_max_depth': 5, 'xgb_subsample': 0.8646586362768911, 'xgb_colsample_bytree': 0.9266736863290774, 'log_reg_C': 0.02650451179943385, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:30,796] Trial 42 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 203, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'xgb_n_estimators': 50, 'xgb_learning_rate': 0.012381285049948643, 'xgb_max_depth': 7, 'xgb_subsample': 0.9493679612555397, 'xgb_colsample_bytree': 0.9018122470848527, 'log_reg_C': 0.037789428515119454, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:32,310] Trial 43 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 255, 'rf_max_depth': 10, 'rf_min_samples_split': 2, 'xgb_n_estimators': 64, 'xgb_learning_rate': 0.014399196614041921, 'xgb_max_depth': 4, 'xgb_subsample': 0.8848742891926713, 'xgb_colsample_bytree': 0.9693132149008914, 'log_reg_C': 0.06116365217232539, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:34,166] Trial 44 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 231, 'rf_max_depth': 14, 'rf_min_samples_split': 5, 'xgb_n_estimators': 110, 'xgb_learning_rate': 0.019368144447576733, 'xgb_max_depth': 9, 'xgb_subsample': 0.8248407291766712, 'xgb_colsample_bytree': 0.9238814453593882, 'log_reg_C': 0.014293358333049785, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:35,897] Trial 45 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 221, 'rf_max_depth': 7, 'rf_min_samples_split': 3, 'xgb_n_estimators': 90, 'xgb_learning_rate': 0.06592869673971673, 'xgb_max_depth': 5, 'xgb_subsample': 0.9090763944768543, 'xgb_colsample_bytree': 0.8543815473019236, 'log_reg_C': 0.028167225701218174, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:37,415] Trial 46 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 188, 'rf_max_depth': 8, 'rf_min_samples_split': 7, 'xgb_n_estimators': 75, 'xgb_learning_rate': 0.03385486436603112, 'xgb_max_depth': 10, 'xgb_subsample': 0.9781170108236582, 'xgb_colsample_bytree': 0.8871001211316992, 'log_reg_C': 0.09606924552947964, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:39,005] Trial 47 finished with value: 0.95050238562519 and parameters: {'rf_n_estimators': 144, 'rf_max_depth': 9, 'rf_min_samples_split': 8, 'xgb_n_estimators': 116, 'xgb_learning_rate': 0.015298395302048138, 'xgb_max_depth': 6, 'xgb_subsample': 0.8678348265979394, 'xgb_colsample_bytree': 0.9807931793221519, 'log_reg_C': 0.16867249248218175, 'log_reg_solver': 'lbfgs'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:42,005] Trial 48 finished with value: 0.9524198078256308 and parameters: {'rf_n_estimators': 282, 'rf_max_depth': 12, 'rf_min_samples_split': 13, 'xgb_n_estimators': 57, 'xgb_learning_rate': 0.01207319645850501, 'xgb_max_depth': 9, 'xgb_subsample': 0.9415179948621077, 'xgb_colsample_bytree': 0.7146434051115657, 'log_reg_C': 0.05867685889365731, 'log_reg_solver': 'liblinear'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:47,473] Trial 49 finished with value: 0.9485430242318662 and parameters: {'rf_n_estimators': 209, 'rf_max_depth': 5, 'rf_min_samples_split': 10, 'xgb_n_estimators': 130, 'xgb_learning_rate': 0.02808093011907194, 'xgb_max_depth': 10, 'xgb_subsample': 0.8461895806692906, 'xgb_colsample_bytree': 0.9447714036036781, 'log_reg_C': 2.1822394894359984, 'log_reg_solver': 'saga'}. Best is trial 11 with value: 0.9542609835857856.\n",
      "[I 2025-04-09 13:44:47,475] A new study created in memory with name: no-name-48977e24-1c1f-49db-9bc7-28568b26ab9e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for Ensemble Model:\n",
      "  Value: 0.9543\n",
      "  Params: \n",
      "    rf_n_estimators: 124\n",
      "    rf_max_depth: 8\n",
      "    rf_min_samples_split: 2\n",
      "    xgb_n_estimators: 227\n",
      "    xgb_learning_rate: 0.02411785491398546\n",
      "    xgb_max_depth: 10\n",
      "    xgb_subsample: 0.9173229807998943\n",
      "    xgb_colsample_bytree: 0.9809914380784289\n",
      "    log_reg_C: 0.03053110065048662\n",
      "    log_reg_solver: liblinear\n",
      "\n",
      "Optimizing Stacking Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-09 13:45:16,656] Trial 0 finished with value: 0.942759737669679 and parameters: {'rf_n_estimators': 209, 'rf_max_depth': 6, 'rf_min_samples_split': 10, 'xgb_n_estimators': 191, 'xgb_learning_rate': 0.02961989390589191, 'xgb_max_depth': 4, 'xgb_subsample': 0.9856293225624563, 'xgb_colsample_bytree': 0.6674659637252496, 'log_reg_C': 0.07368528440631428, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 217, 'final_rf_max_depth': 17}. Best is trial 0 with value: 0.942759737669679.\n",
      "[I 2025-04-09 13:45:40,240] Trial 1 finished with value: 0.9462833429306396 and parameters: {'rf_n_estimators': 262, 'rf_max_depth': 13, 'rf_min_samples_split': 19, 'xgb_n_estimators': 215, 'xgb_learning_rate': 0.11680441378112139, 'xgb_max_depth': 5, 'xgb_subsample': 0.6074470882013117, 'xgb_colsample_bytree': 0.8467693021750542, 'log_reg_C': 7.336936649399507, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 175, 'final_rf_max_depth': 12}. Best is trial 1 with value: 0.9462833429306396.\n",
      "[I 2025-04-09 13:46:05,261] Trial 2 finished with value: 0.9387346898120642 and parameters: {'rf_n_estimators': 218, 'rf_max_depth': 20, 'rf_min_samples_split': 20, 'xgb_n_estimators': 217, 'xgb_learning_rate': 0.012058809069989634, 'xgb_max_depth': 4, 'xgb_subsample': 0.9078071389018213, 'xgb_colsample_bytree': 0.721441029539663, 'log_reg_C': 7.400821756727694, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 275, 'final_rf_max_depth': 10}. Best is trial 1 with value: 0.9462833429306396.\n",
      "[I 2025-04-09 13:46:22,138] Trial 3 finished with value: 0.9446597912684009 and parameters: {'rf_n_estimators': 88, 'rf_max_depth': 15, 'rf_min_samples_split': 13, 'xgb_n_estimators': 167, 'xgb_learning_rate': 0.06229934795530329, 'xgb_max_depth': 7, 'xgb_subsample': 0.717101856573544, 'xgb_colsample_bytree': 0.6560271857744111, 'log_reg_C': 0.021608030831420717, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 256, 'final_rf_max_depth': 8}. Best is trial 1 with value: 0.9462833429306396.\n",
      "[I 2025-04-09 13:46:37,573] Trial 4 finished with value: 0.9467475412880908 and parameters: {'rf_n_estimators': 249, 'rf_max_depth': 20, 'rf_min_samples_split': 14, 'xgb_n_estimators': 89, 'xgb_learning_rate': 0.17422719504339462, 'xgb_max_depth': 10, 'xgb_subsample': 0.7125787491648509, 'xgb_colsample_bytree': 0.852596971487401, 'log_reg_C': 7.513687018872293, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 267, 'final_rf_max_depth': 3}. Best is trial 4 with value: 0.9467475412880908.\n",
      "[I 2025-04-09 13:46:52,324] Trial 5 finished with value: 0.9486127730616886 and parameters: {'rf_n_estimators': 175, 'rf_max_depth': 9, 'rf_min_samples_split': 10, 'xgb_n_estimators': 90, 'xgb_learning_rate': 0.07932479582164688, 'xgb_max_depth': 8, 'xgb_subsample': 0.727654598555995, 'xgb_colsample_bytree': 0.6434094665241331, 'log_reg_C': 1.2464295764828695, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 135, 'final_rf_max_depth': 3}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:47:01,426] Trial 6 finished with value: 0.944376157002802 and parameters: {'rf_n_estimators': 104, 'rf_max_depth': 18, 'rf_min_samples_split': 5, 'xgb_n_estimators': 77, 'xgb_learning_rate': 0.2831013924291632, 'xgb_max_depth': 9, 'xgb_subsample': 0.8069000915487967, 'xgb_colsample_bytree': 0.9308949890593117, 'log_reg_C': 0.7611220885611175, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 55, 'final_rf_max_depth': 11}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:47:10,959] Trial 7 finished with value: 0.944478032537728 and parameters: {'rf_n_estimators': 110, 'rf_max_depth': 10, 'rf_min_samples_split': 19, 'xgb_n_estimators': 91, 'xgb_learning_rate': 0.2595553517924945, 'xgb_max_depth': 10, 'xgb_subsample': 0.6759462819444955, 'xgb_colsample_bytree': 0.9041830821374709, 'log_reg_C': 0.8846734010110174, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 201, 'final_rf_max_depth': 13}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:47:28,806] Trial 8 finished with value: 0.948451140093046 and parameters: {'rf_n_estimators': 152, 'rf_max_depth': 10, 'rf_min_samples_split': 2, 'xgb_n_estimators': 210, 'xgb_learning_rate': 0.21807173682562134, 'xgb_max_depth': 8, 'xgb_subsample': 0.9203820949012465, 'xgb_colsample_bytree': 0.831961849049543, 'log_reg_C': 0.18378011119376791, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 285, 'final_rf_max_depth': 6}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:47:46,710] Trial 9 finished with value: 0.9425170196943624 and parameters: {'rf_n_estimators': 165, 'rf_max_depth': 5, 'rf_min_samples_split': 19, 'xgb_n_estimators': 274, 'xgb_learning_rate': 0.2880953287980381, 'xgb_max_depth': 9, 'xgb_subsample': 0.7129443324678669, 'xgb_colsample_bytree': 0.8668593077383164, 'log_reg_C': 8.149509562666932, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 245, 'final_rf_max_depth': 12}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:47:58,138] Trial 10 finished with value: 0.9407019381971023 and parameters: {'rf_n_estimators': 58, 'rf_max_depth': 3, 'rf_min_samples_split': 8, 'xgb_n_estimators': 138, 'xgb_learning_rate': 0.0605196672079705, 'xgb_max_depth': 6, 'xgb_subsample': 0.798434276529799, 'xgb_colsample_bytree': 0.9966700722225946, 'log_reg_C': 1.4294071862193447, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 131, 'final_rf_max_depth': 20}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:48:16,366] Trial 11 finished with value: 0.9465267193007006 and parameters: {'rf_n_estimators': 155, 'rf_max_depth': 9, 'rf_min_samples_split': 2, 'xgb_n_estimators': 247, 'xgb_learning_rate': 0.11094421258171973, 'xgb_max_depth': 7, 'xgb_subsample': 0.8662750879045467, 'xgb_colsample_bytree': 0.7557482640825343, 'log_reg_C': 0.11400954559980014, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 124, 'final_rf_max_depth': 3}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:48:32,182] Trial 12 finished with value: 0.9483902625687944 and parameters: {'rf_n_estimators': 299, 'rf_max_depth': 9, 'rf_min_samples_split': 3, 'xgb_n_estimators': 134, 'xgb_learning_rate': 0.03084400390338368, 'xgb_max_depth': 8, 'xgb_subsample': 0.9897924424276183, 'xgb_colsample_bytree': 0.7783895278754802, 'log_reg_C': 0.21943578425107288, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 136, 'final_rf_max_depth': 6}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:48:48,032] Trial 13 finished with value: 0.9425767258861442 and parameters: {'rf_n_estimators': 151, 'rf_max_depth': 13, 'rf_min_samples_split': 7, 'xgb_n_estimators': 140, 'xgb_learning_rate': 0.12669248842562664, 'xgb_max_depth': 8, 'xgb_subsample': 0.7982914266642747, 'xgb_colsample_bytree': 0.621421453888474, 'log_reg_C': 2.1184318555927875, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 81, 'final_rf_max_depth': 6}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:48:58,823] Trial 14 finished with value: 0.9426143542256591 and parameters: {'rf_n_estimators': 195, 'rf_max_depth': 7, 'rf_min_samples_split': 15, 'xgb_n_estimators': 62, 'xgb_learning_rate': 0.037390603861448206, 'xgb_max_depth': 6, 'xgb_subsample': 0.8957961989190815, 'xgb_colsample_bytree': 0.6993029709821936, 'log_reg_C': 0.3484737437551741, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 163, 'final_rf_max_depth': 6}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:49:13,129] Trial 15 finished with value: 0.9465697447234671 and parameters: {'rf_n_estimators': 137, 'rf_max_depth': 11, 'rf_min_samples_split': 10, 'xgb_n_estimators': 293, 'xgb_learning_rate': 0.08663110889233082, 'xgb_max_depth': 8, 'xgb_subsample': 0.9402300681221292, 'xgb_colsample_bytree': 0.600317848581205, 'log_reg_C': 0.0357144695351394, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 106, 'final_rf_max_depth': 3}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:49:23,876] Trial 16 finished with value: 0.9425137170010723 and parameters: {'rf_n_estimators': 194, 'rf_max_depth': 15, 'rf_min_samples_split': 5, 'xgb_n_estimators': 168, 'xgb_learning_rate': 0.18510901578485345, 'xgb_max_depth': 9, 'xgb_subsample': 0.7544826401183471, 'xgb_colsample_bytree': 0.7991510076924285, 'log_reg_C': 0.3067990872676023, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 295, 'final_rf_max_depth': 8}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:49:32,035] Trial 17 finished with value: 0.9465603656395633 and parameters: {'rf_n_estimators': 129, 'rf_max_depth': 8, 'rf_min_samples_split': 16, 'xgb_n_estimators': 110, 'xgb_learning_rate': 0.012166442410773805, 'xgb_max_depth': 3, 'xgb_subsample': 0.8443288535662374, 'xgb_colsample_bytree': 0.7306751378675227, 'log_reg_C': 3.115371792279666, 'log_reg_solver': 'liblinear', 'final_rf_n_estimators': 220, 'final_rf_max_depth': 5}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:49:44,677] Trial 18 finished with value: 0.9445538511984525 and parameters: {'rf_n_estimators': 180, 'rf_max_depth': 12, 'rf_min_samples_split': 12, 'xgb_n_estimators': 242, 'xgb_learning_rate': 0.18723379233176418, 'xgb_max_depth': 7, 'xgb_subsample': 0.6493466669783133, 'xgb_colsample_bytree': 0.8094520515554429, 'log_reg_C': 0.6531266604156785, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 191, 'final_rf_max_depth': 8}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:50:24,947] Trial 19 finished with value: 0.9444431509743069 and parameters: {'rf_n_estimators': 226, 'rf_max_depth': 4, 'rf_min_samples_split': 7, 'xgb_n_estimators': 205, 'xgb_learning_rate': 0.04272419045742885, 'xgb_max_depth': 8, 'xgb_subsample': 0.758639096930625, 'xgb_colsample_bytree': 0.9529107132604153, 'log_reg_C': 0.1201310101268025, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 162, 'final_rf_max_depth': 15}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:51:02,382] Trial 20 finished with value: 0.9484603284218791 and parameters: {'rf_n_estimators': 67, 'rf_max_depth': 7, 'rf_min_samples_split': 4, 'xgb_n_estimators': 243, 'xgb_learning_rate': 0.07939318275568433, 'xgb_max_depth': 6, 'xgb_subsample': 0.9603842220051849, 'xgb_colsample_bytree': 0.8284738743357725, 'log_reg_C': 0.010745691127111975, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 296, 'final_rf_max_depth': 5}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:51:27,152] Trial 21 finished with value: 0.9484157618773125 and parameters: {'rf_n_estimators': 53, 'rf_max_depth': 7, 'rf_min_samples_split': 4, 'xgb_n_estimators': 244, 'xgb_learning_rate': 0.020523135155874558, 'xgb_max_depth': 6, 'xgb_subsample': 0.9556286550690062, 'xgb_colsample_bytree': 0.8115574173479486, 'log_reg_C': 0.01252659674817932, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 294, 'final_rf_max_depth': 5}. Best is trial 5 with value: 0.9486127730616886.\n",
      "[I 2025-04-09 13:51:55,402] Trial 22 finished with value: 0.9503471208747094 and parameters: {'rf_n_estimators': 82, 'rf_max_depth': 10, 'rf_min_samples_split': 3, 'xgb_n_estimators': 265, 'xgb_learning_rate': 0.07040485753341034, 'xgb_max_depth': 5, 'xgb_subsample': 0.9384321049771112, 'xgb_colsample_bytree': 0.8401730892893243, 'log_reg_C': 0.010462418969654651, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 234, 'final_rf_max_depth': 4}. Best is trial 22 with value: 0.9503471208747094.\n",
      "[I 2025-04-09 13:52:25,052] Trial 23 finished with value: 0.9484299814104 and parameters: {'rf_n_estimators': 80, 'rf_max_depth': 6, 'rf_min_samples_split': 8, 'xgb_n_estimators': 271, 'xgb_learning_rate': 0.0749651888830435, 'xgb_max_depth': 5, 'xgb_subsample': 0.8539181633076418, 'xgb_colsample_bytree': 0.8958232677469348, 'log_reg_C': 0.012040000080906365, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 234, 'final_rf_max_depth': 4}. Best is trial 22 with value: 0.9503471208747094.\n",
      "[I 2025-04-09 13:52:51,047] Trial 24 finished with value: 0.9503436426248382 and parameters: {'rf_n_estimators': 75, 'rf_max_depth': 11, 'rf_min_samples_split': 5, 'xgb_n_estimators': 269, 'xgb_learning_rate': 0.08757083037593472, 'xgb_max_depth': 5, 'xgb_subsample': 0.9671327910067227, 'xgb_colsample_bytree': 0.7631785758954824, 'log_reg_C': 0.03391201085257399, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 236, 'final_rf_max_depth': 9}. Best is trial 22 with value: 0.9503471208747094.\n",
      "[I 2025-04-09 13:53:22,416] Trial 25 finished with value: 0.9484644188560474 and parameters: {'rf_n_estimators': 108, 'rf_max_depth': 15, 'rf_min_samples_split': 6, 'xgb_n_estimators': 298, 'xgb_learning_rate': 0.04968543209878486, 'xgb_max_depth': 5, 'xgb_subsample': 0.8806351590380278, 'xgb_colsample_bytree': 0.7618573181741252, 'log_reg_C': 0.03622260419381237, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 193, 'final_rf_max_depth': 9}. Best is trial 22 with value: 0.9503471208747094.\n",
      "[I 2025-04-09 13:53:40,859] Trial 26 finished with value: 0.9503379325458761 and parameters: {'rf_n_estimators': 83, 'rf_max_depth': 11, 'rf_min_samples_split': 10, 'xgb_n_estimators': 268, 'xgb_learning_rate': 0.09705213813375173, 'xgb_max_depth': 4, 'xgb_subsample': 0.9956479932344563, 'xgb_colsample_bytree': 0.6758880136062502, 'log_reg_C': 0.02826152551255757, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 227, 'final_rf_max_depth': 14}. Best is trial 22 with value: 0.9503471208747094.\n",
      "[I 2025-04-09 13:53:53,156] Trial 27 finished with value: 0.9484227000823641 and parameters: {'rf_n_estimators': 83, 'rf_max_depth': 13, 'rf_min_samples_split': 9, 'xgb_n_estimators': 269, 'xgb_learning_rate': 0.14392382017890384, 'xgb_max_depth': 3, 'xgb_subsample': 0.9981012121288613, 'xgb_colsample_bytree': 0.6952771040016752, 'log_reg_C': 0.026306245733781798, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 225, 'final_rf_max_depth': 14}. Best is trial 22 with value: 0.9503471208747094.\n",
      "[I 2025-04-09 13:54:07,397] Trial 28 finished with value: 0.952273447518017 and parameters: {'rf_n_estimators': 119, 'rf_max_depth': 11, 'rf_min_samples_split': 6, 'xgb_n_estimators': 283, 'xgb_learning_rate': 0.05667861791180091, 'xgb_max_depth': 4, 'xgb_subsample': 0.9387405750570498, 'xgb_colsample_bytree': 0.7345058855020331, 'log_reg_C': 0.05437529681006572, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 248, 'final_rf_max_depth': 17}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:54:18,901] Trial 29 finished with value: 0.9445080994618017 and parameters: {'rf_n_estimators': 121, 'rf_max_depth': 17, 'rf_min_samples_split': 4, 'xgb_n_estimators': 189, 'xgb_learning_rate': 0.02137904487554372, 'xgb_max_depth': 4, 'xgb_subsample': 0.9446061476556573, 'xgb_colsample_bytree': 0.734488805662448, 'log_reg_C': 0.0635313886918582, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 254, 'final_rf_max_depth': 18}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:54:39,437] Trial 30 finished with value: 0.9503490267256718 and parameters: {'rf_n_estimators': 95, 'rf_max_depth': 12, 'rf_min_samples_split': 6, 'xgb_n_estimators': 284, 'xgb_learning_rate': 0.05301299505436418, 'xgb_max_depth': 5, 'xgb_subsample': 0.9650247314870962, 'xgb_colsample_bytree': 0.7803658660394456, 'log_reg_C': 0.06048879334953145, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 207, 'final_rf_max_depth': 17}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:54:53,744] Trial 31 finished with value: 0.9503490267256718 and parameters: {'rf_n_estimators': 98, 'rf_max_depth': 12, 'rf_min_samples_split': 6, 'xgb_n_estimators': 285, 'xgb_learning_rate': 0.06225880925125543, 'xgb_max_depth': 5, 'xgb_subsample': 0.971595614988323, 'xgb_colsample_bytree': 0.7818390119887229, 'log_reg_C': 0.057557375855318685, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 207, 'final_rf_max_depth': 17}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:55:05,198] Trial 32 finished with value: 0.9503728731468545 and parameters: {'rf_n_estimators': 98, 'rf_max_depth': 12, 'rf_min_samples_split': 6, 'xgb_n_estimators': 289, 'xgb_learning_rate': 0.05008952469576596, 'xgb_max_depth': 5, 'xgb_subsample': 0.9258052617786015, 'xgb_colsample_bytree': 0.7844288634278677, 'log_reg_C': 0.0669984992193696, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 211, 'final_rf_max_depth': 17}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:55:16,121] Trial 33 finished with value: 0.948438666583902 and parameters: {'rf_n_estimators': 101, 'rf_max_depth': 13, 'rf_min_samples_split': 7, 'xgb_n_estimators': 288, 'xgb_learning_rate': 0.04722688822282161, 'xgb_max_depth': 4, 'xgb_subsample': 0.9184238628453034, 'xgb_colsample_bytree': 0.7834680018678629, 'log_reg_C': 0.05542262842257923, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 204, 'final_rf_max_depth': 17}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:55:26,689] Trial 34 finished with value: 0.9446892150829047 and parameters: {'rf_n_estimators': 137, 'rf_max_depth': 14, 'rf_min_samples_split': 6, 'xgb_n_estimators': 225, 'xgb_learning_rate': 0.03324378737975545, 'xgb_max_depth': 3, 'xgb_subsample': 0.969178811112793, 'xgb_colsample_bytree': 0.7114832433952807, 'log_reg_C': 0.09771580880491935, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 176, 'final_rf_max_depth': 19}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:55:37,841] Trial 35 finished with value: 0.9465776264032171 and parameters: {'rf_n_estimators': 97, 'rf_max_depth': 12, 'rf_min_samples_split': 6, 'xgb_n_estimators': 284, 'xgb_learning_rate': 0.022666176005585504, 'xgb_max_depth': 5, 'xgb_subsample': 0.8948326911814066, 'xgb_colsample_bytree': 0.7371493129675135, 'log_reg_C': 0.054978996494079335, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 206, 'final_rf_max_depth': 16}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:56:05,557] Trial 36 finished with value: 0.9483494947083816 and parameters: {'rf_n_estimators': 121, 'rf_max_depth': 16, 'rf_min_samples_split': 8, 'xgb_n_estimators': 253, 'xgb_learning_rate': 0.05700080353281431, 'xgb_max_depth': 4, 'xgb_subsample': 0.9247843603034432, 'xgb_colsample_bytree': 0.7845615580144455, 'log_reg_C': 0.019244391125972284, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 262, 'final_rf_max_depth': 17}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:56:16,093] Trial 37 finished with value: 0.9445404660464118 and parameters: {'rf_n_estimators': 92, 'rf_max_depth': 14, 'rf_min_samples_split': 12, 'xgb_n_estimators': 228, 'xgb_learning_rate': 0.02578383920845641, 'xgb_max_depth': 5, 'xgb_subsample': 0.828553389048782, 'xgb_colsample_bytree': 0.7500085920991415, 'log_reg_C': 0.04800554569745574, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 172, 'final_rf_max_depth': 20}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:56:50,948] Trial 38 finished with value: 0.946690157662807 and parameters: {'rf_n_estimators': 67, 'rf_max_depth': 14, 'rf_min_samples_split': 8, 'xgb_n_estimators': 283, 'xgb_learning_rate': 0.03862424062913201, 'xgb_max_depth': 4, 'xgb_subsample': 0.9749463574654275, 'xgb_colsample_bytree': 0.8759913447952286, 'log_reg_C': 0.08205499155866816, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 272, 'final_rf_max_depth': 18}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:57:01,776] Trial 39 finished with value: 0.9503471208747094 and parameters: {'rf_n_estimators': 121, 'rf_max_depth': 12, 'rf_min_samples_split': 9, 'xgb_n_estimators': 299, 'xgb_learning_rate': 0.05379346420696634, 'xgb_max_depth': 3, 'xgb_subsample': 0.9020496251554689, 'xgb_colsample_bytree': 0.808524293898991, 'log_reg_C': 0.15476207516792723, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 210, 'final_rf_max_depth': 16}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:57:10,937] Trial 40 finished with value: 0.952273447518017 and parameters: {'rf_n_estimators': 112, 'rf_max_depth': 10, 'rf_min_samples_split': 5, 'xgb_n_estimators': 259, 'xgb_learning_rate': 0.061294075631902485, 'xgb_max_depth': 4, 'xgb_subsample': 0.8790866215615287, 'xgb_colsample_bytree': 0.7126849128021984, 'log_reg_C': 0.018942020369911994, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 185, 'final_rf_max_depth': 18}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:57:22,097] Trial 41 finished with value: 0.9427282228368323 and parameters: {'rf_n_estimators': 106, 'rf_max_depth': 10, 'rf_min_samples_split': 6, 'xgb_n_estimators': 256, 'xgb_learning_rate': 0.0684834642400929, 'xgb_max_depth': 4, 'xgb_subsample': 0.9279321993117038, 'xgb_colsample_bytree': 0.662686151167635, 'log_reg_C': 0.019267871093851422, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 185, 'final_rf_max_depth': 18}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:57:36,585] Trial 42 finished with value: 0.9426253930491285 and parameters: {'rf_n_estimators': 138, 'rf_max_depth': 11, 'rf_min_samples_split': 3, 'xgb_n_estimators': 282, 'xgb_learning_rate': 0.044505633708541985, 'xgb_max_depth': 5, 'xgb_subsample': 0.8790070390260512, 'xgb_colsample_bytree': 0.6900208009973218, 'log_reg_C': 0.07802518484800175, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 250, 'final_rf_max_depth': 16}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:58:15,374] Trial 43 finished with value: 0.9503728731468545 and parameters: {'rf_n_estimators': 111, 'rf_max_depth': 9, 'rf_min_samples_split': 5, 'xgb_n_estimators': 232, 'xgb_learning_rate': 0.05860811281212483, 'xgb_max_depth': 4, 'xgb_subsample': 0.9787738438848659, 'xgb_colsample_bytree': 0.7149139467539561, 'log_reg_C': 0.04445589758527496, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 215, 'final_rf_max_depth': 19}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:58:31,268] Trial 44 finished with value: 0.94445819749958 and parameters: {'rf_n_estimators': 114, 'rf_max_depth': 8, 'rf_min_samples_split': 5, 'xgb_n_estimators': 254, 'xgb_learning_rate': 0.0538880057811271, 'xgb_max_depth': 4, 'xgb_subsample': 0.949721054800627, 'xgb_colsample_bytree': 0.7155596454040567, 'log_reg_C': 0.017789316924463807, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 148, 'final_rf_max_depth': 19}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:59:04,698] Trial 45 finished with value: 0.9444159213435416 and parameters: {'rf_n_estimators': 64, 'rf_max_depth': 8, 'rf_min_samples_split': 4, 'xgb_n_estimators': 236, 'xgb_learning_rate': 0.10215583707172277, 'xgb_max_depth': 3, 'xgb_subsample': 0.9827631685435056, 'xgb_colsample_bytree': 0.6360229235778243, 'log_reg_C': 0.042996826959897816, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 218, 'final_rf_max_depth': 19}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:59:44,065] Trial 46 finished with value: 0.944497248759497 and parameters: {'rf_n_estimators': 145, 'rf_max_depth': 9, 'rf_min_samples_split': 7, 'xgb_n_estimators': 204, 'xgb_learning_rate': 0.03694783423451736, 'xgb_max_depth': 4, 'xgb_subsample': 0.9100564762876847, 'xgb_colsample_bytree': 0.7456606041238276, 'log_reg_C': 0.025206403504216466, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 242, 'final_rf_max_depth': 20}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 13:59:56,417] Trial 47 finished with value: 0.9482924955031345 and parameters: {'rf_n_estimators': 130, 'rf_max_depth': 10, 'rf_min_samples_split': 9, 'xgb_n_estimators': 261, 'xgb_learning_rate': 0.027847030504002904, 'xgb_max_depth': 6, 'xgb_subsample': 0.9325027774769278, 'xgb_colsample_bytree': 0.6759582197105284, 'log_reg_C': 0.13733558640310103, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 184, 'final_rf_max_depth': 15}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 14:00:06,438] Trial 48 finished with value: 0.9465606028105631 and parameters: {'rf_n_estimators': 159, 'rf_max_depth': 19, 'rf_min_samples_split': 2, 'xgb_n_estimators': 219, 'xgb_learning_rate': 0.0620065607666806, 'xgb_max_depth': 3, 'xgb_subsample': 0.8918758585747916, 'xgb_colsample_bytree': 0.7151618083831367, 'log_reg_C': 0.01551614330449175, 'log_reg_solver': 'lbfgs', 'final_rf_n_estimators': 280, 'final_rf_max_depth': 12}. Best is trial 28 with value: 0.952273447518017.\n",
      "[I 2025-04-09 14:00:16,188] Trial 49 finished with value: 0.9465760346624468 and parameters: {'rf_n_estimators': 166, 'rf_max_depth': 9, 'rf_min_samples_split': 5, 'xgb_n_estimators': 189, 'xgb_learning_rate': 0.04107515396025597, 'xgb_max_depth': 4, 'xgb_subsample': 0.877763201540193, 'xgb_colsample_bytree': 0.7717121649814197, 'log_reg_C': 0.26519669940153884, 'log_reg_solver': 'saga', 'final_rf_n_estimators': 198, 'final_rf_max_depth': 18}. Best is trial 28 with value: 0.952273447518017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for Stacking Model:\n",
      "  Value: 0.9523\n",
      "  Params: \n",
      "    rf_n_estimators: 119\n",
      "    rf_max_depth: 11\n",
      "    rf_min_samples_split: 6\n",
      "    xgb_n_estimators: 283\n",
      "    xgb_learning_rate: 0.05667861791180091\n",
      "    xgb_max_depth: 4\n",
      "    xgb_subsample: 0.9387405750570498\n",
      "    xgb_colsample_bytree: 0.7345058855020331\n",
      "    log_reg_C: 0.05437529681006572\n",
      "    log_reg_solver: lbfgs\n",
      "    final_rf_n_estimators: 248\n",
      "    final_rf_max_depth: 17\n",
      "\n",
      "Training best models...\n",
      "\n",
      "Best Ensemble Model Accuracy with LDA: 0.9767\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        33\n",
      "           1       0.94      0.97      0.95        32\n",
      "           2       1.00      0.97      0.98        32\n",
      "           3       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           0.98       129\n",
      "   macro avg       0.98      0.98      0.98       129\n",
      "weighted avg       0.98      0.98      0.98       129\n",
      "\n",
      "\n",
      "Best Stacking Model Accuracy with LDA: 0.9612\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        33\n",
      "           1       0.94      0.97      0.95        32\n",
      "           2       1.00      0.94      0.97        32\n",
      "           3       0.97      1.00      0.98        32\n",
      "\n",
      "    accuracy                           0.96       129\n",
      "   macro avg       0.96      0.96      0.96       129\n",
      "weighted avg       0.96      0.96      0.96       129\n",
      "\n",
      "\n",
      "Optimization plots saved as 'ensemble_optuna_results.png' and 'stacking_optuna_results.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASYlJREFUeJzt3Xl8FeX5N+A7BAh7QJBFRNlERBQUJEVBrKKoiHtZVECKWivaKnWBqixawV1sRXGrWrVqq6itC1ao1lr4ueOOK6i1BUElUCggZN4/fHPqIQkQIAOR6/p8zh95zjMzz5znJOfOd+bM5CRJkgQAAAAApKjKlh4AAAAAANseoRQAAAAAqRNKAQAAAJA6oRQAAAAAqRNKAQAAAJA6oRQAAAAAqRNKAQAAAJA6oRQAAAAAqRNKAQAAAJA6oRSU05133hk5OTkxb968zbbOcePGRU5OzmZb39a+3Y1RmcZaHmeccUYcfPDBW3oYqZk3b17k5OTE1Vdfvd6+mzLnAwcOjP79+2/UsgDA98+VV14Z7du3j6Kioi09lNTk5OTEmWeeud5+m/L/zahRo6KgoGAjRgffEkpR6b399ttx0kknRfPmzSMvLy922GGHOPHEE+Ptt9/epPVOmDAhHnnkkc0zyC1o+fLlMW7cuHj22We39FCyrOtDsviD8eWXX96kbfzrX/+KcePGxezZszdpPRVl7ty5cdttt8Uvf/nLTFtxaFPW4/LLL9+CI648LrjggnjooYfi9ddf39JDAahQxZ+ZxY8aNWpEu3bt4swzz4wFCxZs6eFVqJkzZ8a4ceNi8eLFqW2z+IDJokWLUtvm5vZ9qXHLY8mSJXHFFVfEBRdcEFWq/O9f4HXVXKeffvoWHHHlcfbZZ8frr78ef/rTn7b0UKikqm7pAcCmmDp1agwaNCi22267GD58eLRq1SrmzZsXt99+ezz44INx//33xzHHHLNR654wYUIcf/zxcfTRR2e1Dx48OAYOHBh5eXmbYQ++ddFFF8WoUaM22/q+a/ny5TF+/PiIiDjggANS2+7mtjFj/de//hXjx4+Pli1bRufOnStmYJvg+uuvj1atWsUPf/jDEs8NGjQoDj/88BLte+21VxpDq/T22muv6Nq1a1xzzTXxu9/9bksPB6DCXXLJJdGqVatYsWJFPP/883HTTTfFE088EW+99VbUqlVrSw+vQsycOTPGjx8fJ598ctSvX39LD6fSKKvG/T777W9/G6tXr45BgwaVeO7ggw+OIUOGlGhv165dGkOr9Jo2bRpHHXVUXH311XHkkUdu6eFQCQmlqLQ++uijGDx4cLRu3Tqee+652H777TPP/fznP4+ePXvG4MGD44033ojWrVtvtu3m5uZGbm7uZltfRETVqlWjatX0fx231HY3xtY01mXLlkXt2rU3aR3ffPNN3HvvvWUehdt7773jpJNO2qRtbOv69+8fY8eOjRtvvDHq1KmzpYcDUKEOO+yw6Nq1a0REnHLKKdGwYcO49tpr49FHHy31H/ENVVRUFKtWrYoaNWpsrqFu9ZYvX/69C/KSJIkVK1ZEzZo1t/RQtog77rgjjjzyyFLfx+3atVNzbaL+/fvHj370o/j444836/9dbBt8fY9K66qrrorly5fHLbfckhVIRUQ0atQobr755li2bFlceeWVmfbiU67nzJkT/fv3j3r16kXDhg3j5z//eaxYsSLTLycnJ5YtWxZ33XVX5hTek08+OSJK/851y5Yt44gjjohnn302unbtGjVr1ow99tgj85W5qVOnxh577BE1atSILl26xGuvvZY13rWvnXPyySeXeSrxuHHjIiJi1apVMWbMmOjSpUvk5+dH7dq1o2fPnvHMM89k1jNv3rzMazN+/PgS6yjtmj2rV6+OSy+9NNq0aRN5eXnRsmXL+OUvfxkrV67M6le8z88//3x069YtatSoEa1bt66ws1JKG+vTTz8dPXr0iPr160edOnVi1113zXwV7tlnn4199tknIiKGDRuW2fc777wzs/wf//jH6NKlS9SsWTMaNWoUJ510Unz++edZ2zj55JOjTp068dFHH8Xhhx8edevWjRNPPDHGjh0b1apVi4ULF5YY62mnnRb169fPek+t7fnnn49FixZF7969N/Yl2eA5+Oabb2L8+PGxyy67RI0aNaJhw4bRo0ePePrpp7P6zZkzJ44//vjYbrvtokaNGtG1a9cSp2IXv/+ff/75+NnPfhbbb7991K9fP37yk5/EqlWrYvHixTFkyJBo0KBBNGjQIM4///xIkqTU8V933XWx8847R82aNaNXr17x1ltvbdB+33PPPZl522677WLgwIHx2Wefleh38MEHx7Jly0rsJ8C24MADD4yIb78qHhFx9dVXx7777hsNGzaMmjVrRpcuXeLBBx8ssVzx1+vvvffe2H333SMvLy+mTZu2Uev44x//GB06dIiaNWtG9+7d480334yIiJtvvjnatm0bNWrUiAMOOKDU69i88MILceihh0Z+fn7UqlUrevXqFf/4xz8yz48bNy7OO++8iIho1apV5nP+u+vakM+LAw44IDp27BivvPJK7L///lGrVq2sr9VviOJ1vPHGG9GrV6+oVatWtG3bNvPa/O1vf4uCgoKoWbNm7LrrrjF9+vSs5Te0Po0of5321FNPZWrTm2++eZ017ieffBJnnHFG7LrrrlGzZs1o2LBh/OhHPyoxP8W1wD/+8Y8YOXJkbL/99lG7du045phjSq2LnnzyyejVq1fUrVs36tWrF/vss0/8/ve/z+qzvvmOiFi6dGmcffbZ0bJly8jLy4vGjRvHwQcfHK+++uo652fu3LnxxhtvbFLNVTzH77zzTvzwhz+MWrVqRfPmzbP+zyj2m9/8JnbfffeoVatWNGjQILp27Vpifz///PP48Y9/HE2aNIm8vLzYfffd47e//W1Wn2effTZycnLiD3/4Q4wfPz6aN28edevWjeOPPz4KCwtj5cqVcfbZZ0fjxo2jTp06MWzYsBLvg2L33ntv7Lrrrpn/RZ577rkN2u8nn3wyevbsGbVr1466detG3759S71ESvFr++ijj27QeuG7hFJUWn/+85+jZcuW0bNnz1Kf33///aNly5bx+OOPl3iuf//+sWLFipg4cWIcfvjh8etf/zpOO+20zPN333135OXlRc+ePePuu++Ou+++O37yk5+sczwffvhhnHDCCdGvX7+YOHFifP3119GvX7+4995745xzzomTTjopxo8fHx999FH0799/nRdZ/MlPfpLZbvHjxBNPjIiIxo0bR8S3342/7bbb4oADDogrrrgixo0bFwsXLow+ffpkrqG0/fbbx0033RQREcccc0xmXccee2yZ2z7llFNizJgxsffee8d1110XvXr1iokTJ8bAgQNL3efjjz8+Dj744LjmmmuiQYMGcfLJJ2/w9bxWrFgRixYtKvH4z3/+s95l33777TjiiCNi5cqVcckll8Q111wTRx55ZKaA2W233eKSSy6JiG9DouJ933///SPi24Kqf//+kZubGxMnToxTTz01pk6dGj169ChxbYrVq1dHnz59onHjxnH11VfHcccdF4MHD47Vq1fHAw88kNV31apV8eCDD8Zxxx23zqPKM2fOjJycnDK/jrd8+fJSX5vVq1dn9duQORg3blyMHz8+fvjDH8YNN9wQF154Yey0005ZRdzbb78dP/jBD+Ldd9+NUaNGxTXXXBO1a9eOo48+Oh5++OES4zvrrLPigw8+iPHjx8eRRx4Zt9xyS1x88cXRr1+/WLNmTUyYMCF69OgRV111Vdx9990llv/d734Xv/71r2PEiBExevToeOutt+LAAw9c7/VPLrvsshgyZEjssssuce2118bZZ58dM2bMiP3337/EvBX/I7R2UQuwLfjoo48iIqJhw4YR8e1Xxvfaa6+45JJLYsKECVG1atX40Y9+VGqd9Ne//jXOOeecGDBgQFx//fXRsmXLcq/j73//e/ziF7+IoUOHxrhx4+Ldd9+NI444IiZPnhy//vWv44wzzojzzjsvZs2aFT/+8Y9LbH///fePJUuWxNixY2PChAmxePHiOPDAA+PFF1+MiIhjjz02cwbYddddl/mcLz4YV57Piy+//DIOO+yw6Ny5c0yaNKnUr9Wvz9dffx1HHHFEFBQUxJVXXhl5eXkxcODAeOCBB2LgwIFx+OGHx+WXXx7Lli2L448/PpYuXVpiHeurTyPKV6e99957MWjQoDj44IPj+uuvj86dO6+zxn3ppZdi5syZMXDgwPj1r38dp59+esyYMSMOOOCAWL58eYn1n3XWWfH666/H2LFj46c//Wn8+c9/LnG90DvvvDP69u0bX331VYwePTouv/zy6Ny5cybojNiw+Y6IOP300+Omm26K4447Lm688cY499xzo2bNmvHuu++uc25mzpwZEd+ehV6asurRVatWZfX7+uuv49BDD41OnTrFNddcE+3bt48LLrggnnzyyUyfW2+9NX72s59Fhw4dYtKkSTF+/Pjo3LlzvPDCC5k+CxYsiB/84Acxffr0OPPMM+P666+Ptm3bxvDhw2PSpEklxjdx4sR46qmnYtSoUfHjH/84pk6dGqeffnr8+Mc/jvfffz/GjRsXxx57bNx5551xxRVXlFj+b3/7W5x99tlx0kknxSWXXBJffvllHHrooes9GHj33XdH3759o06dOnHFFVfExRdfHO+880706NGjRFCZn58fbdq0UXOxcRKohBYvXpxERHLUUUets9+RRx6ZRESyZMmSJEmSZOzYsUlEJEceeWRWvzPOOCOJiOT111/PtNWuXTsZOnRoiXXecccdSUQkc+fOzbTtvPPOSUQkM2fOzLQ99dRTSUQkNWvWTD755JNM+80335xERPLMM89k2orHVZYPPvggyc/PTw4++OBk9erVSZIkyerVq5OVK1dm9fv666+TJk2aJD/+8Y8zbQsXLkwiIhk7dmyJ9a693dmzZycRkZxyyilZ/c4999wkIpK//vWvJfb5ueeey7R98cUXSV5eXvKLX/yizH0pFhHrfbz00ktljvW6665LIiJZuHBhmdt46aWXkohI7rjjjqz2VatWJY0bN046duyY/Pe//820P/bYY0lEJGPGjMm0DR06NImIZNSoUSXW371796SgoCCrberUqSXmtzQnnXRS0rBhwxLtc+fOXedrMmvWrEzfDZ2DTp06JX379l3neA466KBkjz32SFasWJFpKyoqSvbdd99kl112ybQVv//79OmTFBUVZb0WOTk5yemnn55pW716dbLjjjsmvXr1KrF/NWvWTP75z39m2l944YUkIpJzzjkn07b2nM+bNy/Jzc1NLrvssqyxv/nmm0nVqlVLtCdJkrRr1y457LDD1rnvAJVZ8d/l6dOnJwsXLkw+++yz5P77708aNmyY9bd2+fLlWcutWrUq6dixY3LggQdmtUdEUqVKleTtt98usa3yrCMvLy+rViquf5o2bZqpy5IkSUaPHp1VVxUVFSW77LJLic+Z5cuXJ61atUoOPvjgTNtVV11VoiZLkvJ9XvTq1SuJiGTKlCkl9rc0xZ9N360/itfx+9//PtM2Z86czGv5f//3f5n24vrwu7XJhtanG1OnTZs2rcQ+lFXjrj2/SZIks2bNSiIi+d3vfpdpK37P9e7dO2uOzjnnnCQ3NzdZvHhxkiTf1ut169ZNCgoKsuqtJEkyy5VnvvPz85MRI0aUGOP6XHTRRUlEJEuXLi3x3Lpqrvvuuy/Tr3iOv/s6rFy5MmnatGly3HHHZdqOOuqoZPfdd1/neIYPH540a9YsWbRoUVb7wIEDk/z8/Mw8PPPMM0lEJB07dkxWrVqV6Tdo0KAkJyenRH3TvXv3ZOeddy51/15++eVM2yeffJLUqFEjOeaYYzJta/9/s3Tp0qR+/frJqaeemrW++fPnJ/n5+SXakyRJDjnkkGS33XZb575DaZwpRaVUfHSpbt266+xX/PySJUuy2keMGJH181lnnRUREU888cRGj6lDhw7RvXv3zM/Ft0Y98MADY6eddirR/vHHH2/QepctWxbHHHNMNGjQIO67777M9axyc3OjevXqEfHt9R6++uqrWL16dXTt2nW9pzGXpXj/R44cmdX+i1/8IiKixJHQDh06ZJ2ptv3228euu+66wft21FFHxdNPP13iUXw6/roUX9D00UcfLfetfV9++eX44osv4owzzsg6m6lv377Rvn37Uo/4/vSnPy3RNmTIkHjhhRcyR6Mjvj09ukWLFtGrV691juHLL7+MBg0alPn8aaedVupr06FDh6x+GzIH9evXj7fffjs++OCDUrf11VdfxV//+tfo379/LF26NHOE8Msvv4w+ffrEBx98UOJrjcOHD8/6OmVBQUEkSRLDhw/PtOXm5kbXrl1LfT8cffTR0bx588zP3bp1i4KCgnX+Dk6dOjWKioqif//+WUcymzZtGrvsskvWV1eLNWjQoFLfIQlgQ/Xu3Tu23377aNGiRQwcODDq1KkTDz/8cOZv7XevJfT1119HYWFh9OzZs9SaoVevXiU+b8q7joMOOihzhlXE/+qf4447Lqt+W7sumj17dnzwwQdxwgknxJdffpn5W79s2bI46KCD4rnnnlvv5355Py/y8vJi2LBh61zn+tSpUyfrbKVdd9016tevH7vttltmH0vb3+9aX31a3jqtVatW0adPnw3eh+/O7zfffBNffvlltG3bNurXr1/qHJ922mlZtUDPnj1jzZo18cknn0TEt5dZWLp0aYwaNarE2ePFy5VnvuvXrx8vvPBC/Otf/9rgfYr4tuaqWrVqmdeXLKseXfuMuTp16mRde6p69erRrVu3EjXXP//5z3jppZdK3VaSJPHQQw9Fv379IkmSrPdnnz59orCwsMRrPWTIkKhWrVrm5+Kaa+0zDAsKCuKzzz4rcVZ99+7do0uXLpmfd9pppzjqqKPiqaeeijVr1pQ6zqeffjoWL14cgwYNyhpjbm5uFBQUqLnYrLaOqwZDORUXM6Wd+vxdZYVXu+yyS9bPbdq0iSpVqpR6TYMN9d3gKeLb01gjIlq0aFFq+9dff71B6z311FPjo48+ipkzZ2ZOwS921113xTXXXBNz5syJb775JtPeqlWrco8/4ttrCVSpUiXatm2b1d60adOoX79+psgotvY+R3z7gbSh+7bjjjuW+v3+f/7zn+tddsCAAXHbbbfFKaecEqNGjYqDDjoojj322Dj++OOzbvVbmuL92HXXXUs81759+3j++eez2qpWrRo77rhjqWM4++yz4957740xY8ZEYWFhPPbYY3HOOeeUuP5VaZIyrrUU8e17dEOufbAhc3DJJZfEUUcdFe3atYuOHTvGoYceGoMHD44999wzIr79CmCSJHHxxRfHxRdfXOp2vvjii6wQqTzv99LeD2v/DkZ8e6HRP/zhD2XtanzwwQeRJEmpy0ZEVsFWLEmSDZoLgMpu8uTJ0a5du6hatWo0adIkdt1116zPw8ceeyx+9atfxezZs7OuO1Pa38iy6ojyrGNj66LiAyhDhw4tc18LCwvXeWCnvJ8XzZs3zxzo21g77rhjidchPz+/XHXg+urT8tZp5a0H//vf/8bEiRPjjjvuiM8//zyrTiksLCzRf+05Lp6T4n0rPmjXsWPHMrdZnvm+8sorY+jQodGiRYvo0qVLHH744TFkyJBNvrB2WfVoaf3WnuMGDRrEG2+8kfn5ggsuiOnTp0e3bt2ibdu2ccghh8QJJ5wQ++23X0RELFy4MBYvXhy33HJL3HLLLaVu54svvsj6uTy/S0VFRVFYWJj1P0NZNdfy5ctj4cKF0bRp0xLPF89L8bXp1lavXr0SbWouNpZQikopPz8/mjVrlvUhUJo33ngjmjdvXuofzu/aHH9Ay7ojX1nt6wokil1//fVx3333xT333BOdO3fOeu6ee+6Jk08+OY4++ug477zzonHjxpnrI333zJ2NsaGvx6bs26aqWbNmPPfcc/HMM8/E448/HtOmTYsHHnggDjzwwPjLX/6yWe+QmJeXV2rQ1aBBgzjiiCMyodSDDz4YK1eu3KA7uDRs2HCDw7t12ZA52H///eOjjz6KRx99NP7yl7/EbbfdFtddd11MmTIlTjnllMwRyHPPPbfMI6prF8Dleb9vrvdDUVFR5OTkxJNPPlnqdko7Avr111+X+U8JwPdJt27dMnffW9vf//73OPLII2P//fePG2+8MZo1axbVqlWLO+64o8QFmCOi1Du0lXcdG1sXFX8mXXXVVSVqn2Lru6NqeT8vNscd6SqiDiyrHtvQOq28+3XWWWfFHXfcEWeffXZ079498vPzIycnJwYOHFjq2Wmbow4sz3z3798/evbsGQ8//HD85S9/iauuuiquuOKKmDp1ahx22GFlbqNhw4axevXqWLp06Xq/ZbEuG7K/u+22W7z33nvx2GOPxbRp0+Khhx6KG2+8McaMGRPjx4/P7O9JJ51UZhBXfNBwfdutyDq8eJx33313qaFVaXfE/vrrr6NRo0abvG22PUIpKq0jjjgibr311nj++eejR48eJZ7/+9//HvPmzSv1AuUffPBB1tGjDz/8MIqKirJOM9/SSf/f//73OPfcc+Pss8/OXOT8ux588MFo3bp1TJ06NWusY8eOzepXnv3Yeeedo6ioKD744IPYbbfdMu0LFiyIxYsXx84777wRe1JxqlSpEgcddFAcdNBBce2118aECRPiwgsvjGeeeSZ69+5d5r4X78d7771X4gjQe++9V679HDJkSBx11FHx0ksvxb333ht77bVX7L777utdrn379nHvvfdGYWFh5ohXRdpuu+1i2LBhMWzYsPjPf/4T+++/f4wbNy5OOeWUzBHGatWqbdKdacqjtK8Svv/++1m/g2tr06ZNJEkSrVq1inbt2q13G6tXr47PPvssjjzyyE0ZKkCl99BDD0WNGjXiqaeeiry8vEz7HXfckeo6NkSbNm0i4tszMdb3mVTW53x5Py+2FuurTzdXnVbW6/bggw/G0KFD45prrsm0rVixosSF4TdU8Vy+9dZbJQ5urd1nQ+Y7IqJZs2ZxxhlnxBlnnBFffPFF7L333nHZZZetM5Rq3759RHx7F761A5+KULt27RgwYEAMGDAgVq1aFccee2xcdtllMXr06Nh+++2jbt26sWbNmi1ec9WqVavEHcyLFc9L48aNN3icc+fOjU6dOm38QNlmuaYUldZ5550XNWvWjJ/85Cfx5ZdfZj331Vdfxemnnx61atUq9fpEkydPzvr5N7/5TURE1gda7dq1N/pDeFP9+9//jv79+2fuXlaa4qMj3z0a8sILL8SsWbOy+tWqVSsiYoP25fDDD4+IKHHnj2uvvTYivr3m0tbiq6++KtFWfISt+CsFtWvXjoiS+961a9do3LhxTJkyJevrB08++WS8++675drPww47LBo1ahRXXHFF/O1vf9ugs6Qivv1+f5Ik8corr2zwtjbW2r8fderUibZt22b2vXHjxnHAAQfEzTffHP/+979LLF/a7Z031SOPPJJ1naoXX3wxXnjhhXUWlccee2zk5ubG+PHjSxwFTJKkxH6+8847sWLFith333037+ABKpnc3NzIycnJun7MvHnz4pFHHkl1HRuiS5cu0aZNm7j66qtLvRvvdz+TyvqcL+/nxdZiffXp5qrTyqpxc3NzS7xev/nNb8q87tD6HHLIIVG3bt2YOHFirFixIuu54u1s6HyvWbOmxFcIGzduHDvssENWLVea4mu+vvzyyxu1H+Wx9nurevXq0aFDh0iSJL755pvIzc2N4447Lh566KFS735XETXXrFmzsq5T9dlnn8Wjjz4ahxxySJlnW/Xp0yfq1asXEyZMyLpESFnjLCwsjI8++kjNxUZxphSV1i677BJ33XVXnHjiibHHHnvE8OHDo1WrVjFv3ry4/fbbY9GiRXHfffdlkv7vmjt3bhx55JFx6KGHxqxZs+Kee+6JE044ISvd79KlS0yfPj2uvfba2GGHHaJVq1ZZF6qsSD/72c9i4cKFcf7558f999+f9dyee+4Ze+65ZxxxxBExderUOOaYY6Jv374xd+7cmDJlSnTo0CHrQ71mzZrRoUOHeOCBB6Jdu3ax3XbbRceOHUv9fn+nTp1i6NChccstt8TixYujV69e8eKLL8Zdd90VRx999EbdIrmiXHLJJfHcc89F3759Y+edd44vvvgibrzxxthxxx0zZ861adMm6tevH1OmTIm6detG7dq1o6CgIFq1ahVXXHFFDBs2LHr16hWDBg2KBQsWZG57fc4552zwOKpVqxYDBw6MG264IXJzczO3p16fHj16RMOGDWP69Omlfl//1VdfjXvuuadEe5s2bbIuqL8hOnToEAcccEB06dIltttuu3j55ZfjwQcfzLpt8+TJk6NHjx6xxx57xKmnnhqtW7eOBQsWxKxZs+Kf//xnvP766+Xa5vq0bds2evToET/96U9j5cqVMWnSpGjYsGGcf/75ZS7Tpk2b+NWvfhWjR4+OefPmxdFHHx1169aNuXPnxsMPPxynnXZanHvuuZn+Tz/9dNSqVSsOPvjgzTp2gMqmb9++ce2118ahhx4aJ5xwQnzxxRcxefLkaNu27XovhbA517EhqlSpErfddlscdthhsfvuu8ewYcOiefPm8fnnn8czzzwT9erViz//+c8REZmLN1944YUxcODAqFatWvTr16/cnxdbi/XVp5urTiurxj3iiCPi7rvvjvz8/OjQoUPMmjUrpk+fXuKaphuqXr16cd1118Upp5wS++yzT5xwwgnRoEGDeP3112P58uVx1113bfB8L126NHbcccc4/vjjo1OnTlGnTp2YPn16vPTSS1lndpWmdevW0bFjx5g+fXqJi4NHfHvWUGk1V5MmTcpdQxxyyCHRtGnT2G+//aJJkybx7rvvxg033BB9+/bNfHXw8ssvj2eeeSYKCgri1FNPjQ4dOsRXX30Vr776akyfPr3UA6+bomPHjtGnT5/42c9+Fnl5eXHjjTdGRMT48ePLXKZevXpx0003xeDBg2PvvfeOgQMHxvbbbx+ffvppPP7447HffvvFDTfckOk/ffr0SJIkjjrqqM06drYRFX+DP6hYb7zxRjJo0KCkWbNmSbVq1ZKmTZsmgwYNSt58880SfYtvufvOO+8kxx9/fFK3bt2kQYMGyZlnnlniVrVz5sxJ9t9//6RmzZpJRGRunbv2LVOT5Nvb7vbt27fE9iKixK1r586dm0REctVVV5UYV7Hi286W9hg7dmySJN/eQnfChAnJzjvvnOTl5SV77bVX8thjjyVDhw4tcTvYmTNnJl26dEmqV6+etY61t5skSfLNN98k48ePT1q1apVUq1YtadGiRTJ69OhkxYoVWf3K2udevXolvXr1KtG+Ia9NseLX+KWXXirzNZoxY0Zy1FFHJTvssENSvXr1ZIcddkgGDRqUvP/++1nrevTRR5MOHTokVatWLXEL5gceeCDZa6+9kry8vGS77bZLTjzxxMyts4sNHTo0qV279jr35cUXX0wiIjnkkEPWu9/f9bOf/Sxp27ZtVlvx+6Osx3dv4byhc/CrX/0q6datW1K/fv2kZs2aSfv27ZPLLrss6/bCSZIkH330UTJkyJCkadOmSbVq1ZLmzZsnRxxxRPLggw9m+pQ2N0lS+i2yk6Tk6/fd9/8111yTtGjRIsnLy0t69uyZueX12utc20MPPZT06NEjqV27dlK7du2kffv2yYgRI5L33nsvq19BQUFy0kknlVge4PukrL/La7v99tuTXXbZJcnLy0vat2+f3HHHHaX+nV3X5/OmrKO0+idJ/nfb+z/+8Y9Z7a+99lpy7LHHJg0bNkzy8vKSnXfeOenfv38yY8aMrH6XXnpp0rx586RKlSol6rMN+bzo1atXsvvuu6/ztfuu0j7vylrHhtaH5alPN7VOS5Kya9yvv/46GTZsWNKoUaOkTp06SZ8+fZI5c+YkO++8c1b9UdZ7rngun3nmmaz2P/3pT8m+++6b1KxZM6lXr17SrVu35L777svqs775XrlyZXLeeeclnTp1SurWrZvUrl076dSpU3LjjTeWuo9ru/baa5M6deoky5cvz2pfV8313VqqrDleu+6++eabk/333z+zH23atEnOO++8pLCwMGu5BQsWJCNGjEhatGiR+f/loIMOSm655ZYSr+favxvlqcWK32v33HNP5nd3r732KjFHpf1/UzyGPn36JPn5+UmNGjWSNm3aJCeffHLy8ssvZ/UbMGBA0qNHjxKvD2yInCRJ4YrEsJUYN25cjB8/PhYuXOhCfGw2r7/+enTu3Dl+97vfxeDBgzd4uY8//jjat28fTz75ZBx00EEVOMJtz+zZs2PvvfeOV199tcwLpwLA1kB9WvEKCwujdevWceWVV8bw4cO39HC+V+bPnx+tWrWK+++/35lSbBTXlALYRLfeemvUqVMnjj322HIt17p16xg+fHhcfvnlFTSybdfll18exx9/vEAKAIj8/Pw4//zz46qrrir1ToJsvEmTJsUee+whkGKjuaYUwEb685//HO+8807ccsstceaZZ2YuuFoeN910UwWMjLWvxQYAbNsuuOCCuOCCC7b0ML53HFxlUwmlADbSWWedFQsWLIjDDz98nReLBAAAoKRyf33vueeei379+sUOO+wQOTk5G3Qb2GeffTb23nvvyMvLi7Zt28add965EUOFTTdu3LhIksT39dks5s2bF//973/jkUceydxRBaA06iegLOpTYFtW7lBq2bJl0alTp5g8efIG9Z87d2707ds3fvjDH8bs2bPj7LPPjlNOOSWeeuqpcg8WAKAyUj8BAJS0SXffy8nJiYcffjiOPvroMvtccMEF8fjjj8dbb72VaRs4cGAsXrw4pk2btrGbBgColNRPAADfqvBrSs2aNSt69+6d1danT584++yzy1xm5cqVsXLlyszPRUVF8dVXX0XDhg0jJyenooYKAGwjkiSJpUuXxg477BBVqmx9NyNWPwEAW5uKqJ8qPJSaP39+NGnSJKutSZMmsWTJkvjvf/8bNWvWLLHMxIkTXTQYAKhwn332Wey4445behglqJ8AgK3V5qyftsq7740ePTpGjhyZ+bmwsDB22mmn+Oyzz6JevXpbcGQAwPfBkiVLokWLFt+rmxSonwCAilQR9VOFh1JNmzaNBQsWZLUtWLAg6tWrV+pRvoiIvLy8yMvLK9Fer149RRUAsNlsrV9rUz8BAFurzVk/VfhFFLp37x4zZszIanv66aeje/fuFb1pAIBKSf0EAGwLyh1K/ec//4nZs2fH7NmzI+LbWxbPnj07Pv3004j49tTxIUOGZPqffvrp8fHHH8f5558fc+bMiRtvvDH+8Ic/xDnnnLN59gAAYCunfgIAKKncodTLL78ce+21V+y1114RETFy5MjYa6+9YsyYMRER8e9//ztTYEVEtGrVKh5//PF4+umno1OnTnHNNdfEbbfdFn369NlMuwAAsHVTPwEAlJSTJEmypQexPkuWLIn8/PwoLCx0TQQAYJNtC7XFtrCPAEB6KqK2qPBrSgEAAADA2oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKROKAUAAABA6oRSAAAAAKRuo0KpyZMnR8uWLaNGjRpRUFAQL7744jr7T5o0KXbdddeoWbNmtGjRIs4555xYsWLFRg0YAKAyUj8BAGQrdyj1wAMPxMiRI2Ps2LHx6quvRqdOnaJPnz7xxRdflNr/97//fYwaNSrGjh0b7777btx+++3xwAMPxC9/+ctNHjwAQGWgfgIAKKncodS1114bp556agwbNiw6dOgQU6ZMiVq1asVvf/vbUvvPnDkz9ttvvzjhhBOiZcuWccghh8SgQYPWe3QQAOD7Qv0EAFBSuUKpVatWxSuvvBK9e/f+3wqqVInevXvHrFmzSl1m3333jVdeeSVTRH388cfxxBNPxOGHH17mdlauXBlLlizJegAAVEbqJwCA0lUtT+dFixbFmjVrokmTJlntTZo0iTlz5pS6zAknnBCLFi2KHj16RJIksXr16jj99NPXefr5xIkTY/z48eUZGgDAVkn9BABQugq/+96zzz4bEyZMiBtvvDFeffXVmDp1ajz++ONx6aWXlrnM6NGjo7CwMPP47LPPKnqYAABbDfUTALAtKNeZUo0aNYrc3NxYsGBBVvuCBQuiadOmpS5z8cUXx+DBg+OUU06JiIg99tgjli1bFqeddlpceOGFUaVKyVwsLy8v8vLyyjM0AICtkvoJAKB05TpTqnr16tGlS5eYMWNGpq2oqChmzJgR3bt3L3WZ5cuXlyiccnNzIyIiSZLyjhcAoFJRPwEAlK5cZ0pFRIwcOTKGDh0aXbt2jW7dusWkSZNi2bJlMWzYsIiIGDJkSDRv3jwmTpwYERH9+vWLa6+9Nvbaa68oKCiIDz/8MC6++OLo169fprgCAPg+Uz8BAJRU7lBqwIABsXDhwhgzZkzMnz8/OnfuHNOmTctcvPPTTz/NOrJ30UUXRU5OTlx00UXx+eefx/bbbx/9+vWLyy67bPPtBQDAVkz9BABQUk5SCc4BX7JkSeTn50dhYWHUq1dvSw8HAKjktoXaYlvYRwAgPRVRW1T43fcAAAAAYG1CKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHVCKQAAAABSJ5QCAAAAIHUbFUpNnjw5WrZsGTVq1IiCgoJ48cUX19l/8eLFMWLEiGjWrFnk5eVFu3bt4oknntioAQMAVEbqJwCAbFXLu8ADDzwQI0eOjClTpkRBQUFMmjQp+vTpE++99140bty4RP9Vq1bFwQcfHI0bN44HH3wwmjdvHp988knUr19/c4wfAGCrp34CACgpJ0mSpDwLFBQUxD777BM33HBDREQUFRVFixYt4qyzzopRo0aV6D9lypS46qqrYs6cOVGtWrWNGuSSJUsiPz8/CgsLo169ehu1DgCAYmnXFuonAKCyq4jaolxf31u1alW88sor0bt37/+toEqV6N27d8yaNavUZf70pz9F9+7dY8SIEdGkSZPo2LFjTJgwIdasWbNpIwcAqATUTwAApSvX1/cWLVoUa9asiSZNmmS1N2nSJObMmVPqMh9//HH89a9/jRNPPDGeeOKJ+PDDD+OMM86Ib775JsaOHVvqMitXroyVK1dmfl6yZEl5hgkAsNVQPwEAlK7C775XVFQUjRs3jltuuSW6dOkSAwYMiAsvvDCmTJlS5jITJ06M/Pz8zKNFixYVPUwAgK2G+gkA2BaUK5Rq1KhR5ObmxoIFC7LaFyxYEE2bNi11mWbNmkW7du0iNzc307bbbrvF/PnzY9WqVaUuM3r06CgsLMw8Pvvss/IMEwBgq6F+AgAoXblCqerVq0eXLl1ixowZmbaioqKYMWNGdO/evdRl9ttvv/jwww+jqKgo0/b+++9Hs2bNonr16qUuk5eXF/Xq1ct6AABURuonAIDSlfvreyNHjoxbb7017rrrrnj33Xfjpz/9aSxbtiyGDRsWERFDhgyJ0aNHZ/r/9Kc/ja+++ip+/vOfx/vvvx+PP/54TJgwIUaMGLH59gIAYCumfgIAKKlcFzqPiBgwYEAsXLgwxowZE/Pnz4/OnTvHtGnTMhfv/PTTT6NKlf9lXS1atIinnnoqzjnnnNhzzz2jefPm8fOf/zwuuOCCzbcXAABbMfUTAEBJOUmSJFt6EOuzZMmSyM/Pj8LCQqeiAwCbbFuoLbaFfQQA0lMRtUWF330PAAAAANYmlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdUIpAAAAAFInlAIAAAAgdRsVSk2ePDlatmwZNWrUiIKCgnjxxRc3aLn7778/cnJy4uijj96YzQIAVGpqKACA/yl3KPXAAw/EyJEjY+zYsfHqq69Gp06dok+fPvHFF1+sc7l58+bFueeeGz179tzowQIAVFZqKACAbOUOpa699to49dRTY9iwYdGhQ4eYMmVK1KpVK37729+WucyaNWvixBNPjPHjx0fr1q03acAAAJWRGgoAIFu5QqlVq1bFK6+8Er179/7fCqpUid69e8esWbPKXO6SSy6Jxo0bx/Dhwzd+pAAAlZQaCgCgpKrl6bxo0aJYs2ZNNGnSJKu9SZMmMWfOnFKXef755+P222+P2bNnb/B2Vq5cGStXrsz8vGTJkvIMEwBgq5JGDaV+AgAqmwq9+97SpUtj8ODBceutt0ajRo02eLmJEydGfn5+5tGiRYsKHCUAwNZlY2oo9RMAUNmU60ypRo0aRW5ubixYsCCrfcGCBdG0adMS/T/66KOYN29e9OvXL9NWVFT07YarVo333nsv2rRpU2K50aNHx8iRIzM/L1myRGEFAFRaadRQ6icAoLIpVyhVvXr16NKlS8yYMSNzS+KioqKYMWNGnHnmmSX6t2/fPt58882stosuuiiWLl0a119/fZmFUl5eXuTl5ZVnaAAAW600aij1EwBQ2ZQrlIqIGDlyZAwdOjS6du0a3bp1i0mTJsWyZcti2LBhERExZMiQaN68eUycODFq1KgRHTt2zFq+fv36EREl2gEAvs/UUAAA2codSg0YMCAWLlwYY8aMifnz50fnzp1j2rRpmQt3fvrpp1GlSoVeqgoAoNJRQwEAZMtJkiTZ0oNYnyVLlkR+fn4UFhZGvXr1tvRwAIBKbluoLbaFfQQA0lMRtYXDcQAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOqEUgAAAACkTigFAAAAQOo2KpSaPHlytGzZMmrUqBEFBQXx4osvltn31ltvjZ49e0aDBg2iQYMG0bt373X2BwD4vlJDAQD8T7lDqQceeCBGjhwZY8eOjVdffTU6deoUffr0iS+++KLU/s8++2wMGjQonnnmmZg1a1a0aNEiDjnkkPj88883efAAAJWFGgoAIFtOkiRJeRYoKCiIffbZJ2644YaIiCgqKooWLVrEWWedFaNGjVrv8mvWrIkGDRrEDTfcEEOGDNmgbS5ZsiTy8/OjsLAw6tWrV57hAgCUsCVqi7RrKPUTALA5VURtUa4zpVatWhWvvPJK9O7d+38rqFIlevfuHbNmzdqgdSxfvjy++eab2G677crss3LlyliyZEnWAwCgskqjhlI/AQCVTblCqUWLFsWaNWuiSZMmWe1NmjSJ+fPnb9A6Lrjggthhhx2yirK1TZw4MfLz8zOPFi1alGeYAABblTRqKPUTAFDZpHr3vcsvvzzuv//+ePjhh6NGjRpl9hs9enQUFhZmHp999lmKowQA2LpsSA2lfgIAKpuq5encqFGjyM3NjQULFmS1L1iwIJo2bbrOZa+++uq4/PLLY/r06bHnnnuus29eXl7k5eWVZ2gAAFutNGoo9RMAUNmU60yp6tWrR5cuXWLGjBmZtqKiopgxY0Z07969zOWuvPLKuPTSS2PatGnRtWvXjR8tAEAlpIYCACipXGdKRUSMHDkyhg4dGl27do1u3brFpEmTYtmyZTFs2LCIiBgyZEg0b948Jk6cGBERV1xxRYwZMyZ+//vfR8uWLTPXTahTp07UqVNnM+4KAMDWSw0FAJCt3KHUgAEDYuHChTFmzJiYP39+dO7cOaZNm5a5cOenn34aVar87wSsm266KVatWhXHH3981nrGjh0b48aN27TRAwBUEmooAIBsOUmSJFt6EOuzZMmSyM/Pj8LCwqhXr96WHg4AUMltC7XFtrCPAEB6KqK2SPXuewAAAAAQIZQCAAAAYAsQSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKkTSgEAAACQOqEUAAAAAKnbqFBq8uTJ0bJly6hRo0YUFBTEiy++uM7+f/zjH6N9+/ZRo0aN2GOPPeKJJ57YqMECAFRmaigAgP8pdyj1wAMPxMiRI2Ps2LHx6quvRqdOnaJPnz7xxRdflNp/5syZMWjQoBg+fHi89tprcfTRR8fRRx8db7311iYPHgCgslBDAQBky0mSJCnPAgUFBbHPPvvEDTfcEBERRUVF0aJFizjrrLNi1KhRJfoPGDAgli1bFo899lim7Qc/+EF07tw5pkyZskHbXLJkSeTn50dhYWHUq1evPMMFAChhS9QWaddQ6icAYHOqiNqiank6r1q1Kl555ZUYPXp0pq1KlSrRu3fvmDVrVqnLzJo1K0aOHJnV1qdPn3jkkUfK3M7KlStj5cqVmZ8LCwsj4tsXAABgUxXXFOU8NrfR0qih1E8AQEWqiPqpXKHUokWLYs2aNdGkSZOs9iZNmsScOXNKXWb+/Pml9p8/f36Z25k4cWKMHz++RHuLFi3KM1wAgHX68ssvIz8/v8K3k0YNpX4CANKwOeuncoVSaRk9enTWkcHFixfHzjvvHJ9++mkqhSMbb8mSJdGiRYv47LPPfFVgK2euKg9zVXmYq8qjsLAwdtppp9huu+229FA2G/VT5eVvR+VhrioPc1V5mKvKoyLqp3KFUo0aNYrc3NxYsGBBVvuCBQuiadOmpS7TtGnTcvWPiMjLy4u8vLwS7fn5+d6klUS9evXMVSVhrioPc1V5mKvKo0qVjboRcbmlUUOpnyo/fzsqD3NVeZirysNcVR6bs34q15qqV68eXbp0iRkzZmTaioqKYsaMGdG9e/dSl+nevXtW/4iIp59+usz+AADfN2ooAICSyv31vZEjR8bQoUOja9eu0a1bt5g0aVIsW7Yshg0bFhERQ4YMiebNm8fEiRMjIuLnP/959OrVK6655pro27dv3H///fHyyy/HLbfcsnn3BABgK6aGAgDIVu5QasCAAbFw4cIYM2ZMzJ8/Pzp37hzTpk3LXIjz008/zTqVa999943f//73cdFFF8Uvf/nL2GWXXeKRRx6Jjh07bvA28/LyYuzYsaWeks7WxVxVHuaq8jBXlYe5qjy2xFylXUN5P1Ye5qryMFeVh7mqPMxV5VERc5WTpHUvZAAAAAD4/9K5uicAAAAAfIdQCgAAAIDUCaUAAAAASJ1QCgAAAIDUbTWh1OTJk6Nly5ZRo0aNKCgoiBdffHGd/f/4xz9G+/bto0aNGrHHHnvEE088kdJIKc9c3XrrrdGzZ89o0KBBNGjQIHr37r3euWXzKe/vVbH7778/cnJy4uijj67YARIR5Z+nxYsXx4gRI6JZs2aRl5cX7dq18zcwJeWdq0mTJsWuu+4aNWvWjBYtWsQ555wTK1asSGm0267nnnsu+vXrFzvssEPk5OTEI488st5lnn322dh7770jLy8v2rZtG3feeWeFj3NzUD9VHuqnykP9VHmooSoPNVTlsEVqqGQrcP/99yfVq1dPfvvb3yZvv/12cuqppyb169dPFixYUGr/f/zjH0lubm5y5ZVXJu+8805y0UUXJdWqVUvefPPNlEe+7SnvXJ1wwgnJ5MmTk9deey159913k5NPPjnJz89P/vnPf6Y88m1Peeeq2Ny5c5PmzZsnPXv2TI466qh0BrsNK+88rVy5MunatWty+OGHJ88//3wyd+7c5Nlnn01mz56d8si3PeWdq3vvvTfJy8tL7r333mTu3LnJU089lTRr1iw555xzUh75tueJJ55ILrzwwmTq1KlJRCQPP/zwOvt//PHHSa1atZKRI0cm77zzTvKb3/wmyc3NTaZNm5bOgDeS+qnyUD9VHuqnykMNVXmooSqPLVFDbRWhVLdu3ZIRI0Zkfl6zZk2yww47JBMnTiy1f//+/ZO+fftmtRUUFCQ/+clPKnSclH+u1rZ69eqkbt26yV133VVRQ+T/25i5Wr16dbLvvvsmt912WzJ06FBFVQrKO0833XRT0rp162TVqlVpDZH/r7xzNWLEiOTAAw/Mahs5cmSy3377Veg4ybYhBdX555+f7L777lltAwYMSPr06VOBI9t06qfKQ/1UeaifKg81VOWhhqqc0qqhtvjX91atWhWvvPJK9O7dO9NWpUqV6N27d8yaNavUZWbNmpXVPyKiT58+ZfZn89iYuVrb8uXL45tvvontttuuooZJbPxcXXLJJdG4ceMYPnx4GsPc5m3MPP3pT3+K7t27x4gRI6JJkybRsWPHmDBhQqxZsyatYW+TNmau9t1333jllVcyp6d//PHH8cQTT8Thhx+eypjZcJWxrlA/VR7qp8pD/VR5qKEqDzXU99vmqC2qbu5BldeiRYtizZo10aRJk6z2Jk2axJw5c0pdZv78+aX2nz9/foWNk42bq7VdcMEFscMOO5R447J5bcxcPf/883H77bfH7NmzUxghERs3Tx9//HH89a9/jRNPPDGeeOKJ+PDDD+OMM86Ib775JsaOHZvGsLdJGzNXJ5xwQixatCh69OgRSZLE6tWr4/TTT49f/vKXaQyZciirrliyZEn897//jZo1a26hkZVN/VR5qJ8qD/VT5aGGqjzUUN9vm6OG2uJnSrHtuPzyy+P++++Phx9+OGrUqLGlh8N3LF26NAYPHhy33nprNGrUaEsPh3UoKiqKxo0bxy233BJdunSJAQMGxIUXXhhTpkzZ0kNjLc8++2xMmDAhbrzxxnj11Vdj6tSp8fjjj8ell166pYcGVCLqp62X+qlyUUNVHmqobcsWP1OqUaNGkZubGwsWLMhqX7BgQTRt2rTUZZo2bVqu/mweGzNXxa6++uq4/PLLY/r06bHnnntW5DCJ8s/VRx99FPPmzYt+/fpl2oqKiiIiomrVqvHee+9FmzZtKnbQ26CN+Z1q1qxZVKtWLXJzczNtu+22W8yfPz9WrVoV1atXr9Axb6s2Zq4uvvjiGDx4cJxyyikREbHHHnvEsmXL4rTTTosLL7wwqlRxXGhrUVZdUa9eva3yLKkI9VNlon6qPNRPlYcaqvJQQ32/bY4aaovPZvXq1aNLly4xY8aMTFtRUVHMmDEjunfvXuoy3bt3z+ofEfH000+X2Z/NY2PmKiLiyiuvjEsvvTSmTZsWXbt2TWOo27zyzlX79u3jzTffjNmzZ2ceRx55ZPzwhz+M2bNnR4sWLdIc/jZjY36n9ttvv/jwww8zRW9ExPvvvx/NmjVTTFWgjZmr5cuXlyiaigvhb68dydaiMtYV6qfKQ/1UeaifKg81VOWhhvp+2yy1RXmvwF4R7r///iQvLy+58847k3feeSc57bTTkvr16yfz589PkiRJBg8enIwaNSrT/x//+EdStWrV5Oqrr07efffdZOzYsW5pnJLyztXll1+eVK9ePXnwwQeTf//735nH0qVLt9QubDPKO1drc/eYdJR3nj799NOkbt26yZlnnpm89957yWOPPZY0btw4+dWvfrWldmGbUd65Gjt2bFK3bt3kvvvuSz7++OPkL3/5S9KmTZukf//+W2oXthlLly5NXnvtteS1115LIiK59tprk9deey355JNPkiRJklGjRiWDBw/O9C++nfF5552XvPvuu8nkyZPLfTvjLUH9VHmonyoP9VPloYaqPNRQlceWqKG2ilAqSZLkN7/5TbLTTjsl1atXT7p165b83//9X+a5Xr16JUOHDs3q/4c//CFp165dUr169WT33XdPHn/88ZRHvO0qz1ztvPPOSUSUeIwdOzb9gW+Dyvt79V2KqvSUd55mzpyZFBQUJHl5eUnr1q2Tyy67LFm9enXKo942lWeuvvnmm2TcuHFJmzZtkho1aiQtWrRIzjjjjOTrr79Of+DbmGeeeabUz57i+Rk6dGjSq1evEst07tw5qV69etK6devkjjvuSH3cG0P9VHmonyoP9VPloYaqPNRQlcOWqKFyksT5bwAAAACka4tfUwoAAACAbY9QCgAAAIDUCaUAAAAASJ1QCgAAAIDUCaUAAAAASJ1QCgAAAIDUCaUAAAAASJ1QCgAAAIDUCaUAAAAASJ1QCgAAAIDUCaUAAAAASJ1QCgAAAIDU/T8N/WjD3WqNMAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"D:\\mlpr data\\Glioblastoma-ML-model\\stackAndModel\\merged_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert target column to numeric\n",
    "df[\"Survival_from_surgery_days_UPDATED\"] = pd.to_numeric(df[\"Survival_from_surgery_days_UPDATED\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df = df.dropna(subset=[\"Survival_from_surgery_days_UPDATED\"])\n",
    "\n",
    "# Percentile-Based Binning\n",
    "percentiles = np.percentile(df[\"Survival_from_surgery_days_UPDATED\"], [25, 50, 75])\n",
    "bins = [0, percentiles[0], percentiles[1], percentiles[2], np.inf]\n",
    "labels = [0, 1, 2, 3]\n",
    "\n",
    "df[\"Survival_Category\"] = pd.cut(df[\"Survival_from_surgery_days_UPDATED\"], bins=bins, labels=labels)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[\"PatientID\", \"Survival_from_surgery_days_UPDATED\", \"Survival_Category\"])\n",
    "y = df[\"Survival_Category\"]\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(X.median())\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply LDA for dimensionality reduction\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)  # Adjust components based on the number of classes - 1\n",
    "X_lda = lda.fit_transform(X_scaled, y)\n",
    "\n",
    "# Train-test split (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Balance Classes with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the objective function for Optuna (Ensemble Model)\n",
    "def objective_ensemble(trial):\n",
    "    # Hyperparameters for Random Forest\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 50, 300)\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 3, 20)\n",
    "    rf_min_samples_split = trial.suggest_int('rf_min_samples_split', 2, 20)\n",
    "    \n",
    "    # Hyperparameters for XGBoost\n",
    "    xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 50, 300)\n",
    "    xgb_learning_rate = trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True)\n",
    "    xgb_max_depth = trial.suggest_int('xgb_max_depth', 3, 10)\n",
    "    xgb_subsample = trial.suggest_float('xgb_subsample', 0.6, 1.0)\n",
    "    xgb_colsample_bytree = trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0)\n",
    "    \n",
    "    # Hyperparameters for Logistic Regression\n",
    "    log_reg_C = trial.suggest_float('log_reg_C', 0.01, 10.0, log=True)\n",
    "    log_reg_solver = trial.suggest_categorical('log_reg_solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "    \n",
    "    # Define models with the suggested hyperparameters\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=rf_n_estimators,\n",
    "        max_depth=rf_max_depth,\n",
    "        min_samples_split=rf_min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        n_estimators=xgb_n_estimators,\n",
    "        learning_rate=xgb_learning_rate,\n",
    "        max_depth=xgb_max_depth,\n",
    "        subsample=xgb_subsample,\n",
    "        colsample_bytree=xgb_colsample_bytree,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    log_reg = LogisticRegression(\n",
    "        C=log_reg_C,\n",
    "        solver=log_reg_solver,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    lda_clf = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    # Create the ensemble model\n",
    "    ensemble_model = VotingClassifier(\n",
    "        estimators=[(\"RandomForest\", rf_clf), (\"XGBoost\", xgb_clf), (\"LogReg\", log_reg), (\"LDA\", lda_clf)],\n",
    "        voting=\"soft\"\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        ensemble_model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = ensemble_model.predict(X_val_fold)\n",
    "        score = f1_score(y_val_fold, y_pred, average='weighted')\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Define the objective function for Optuna (Stacking Model)\n",
    "def objective_stacking(trial):\n",
    "    # Hyperparameters for Random Forest\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 50, 300)\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 3, 20)\n",
    "    rf_min_samples_split = trial.suggest_int('rf_min_samples_split', 2, 20)\n",
    "    \n",
    "    # Hyperparameters for XGBoost\n",
    "    xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 50, 300)\n",
    "    xgb_learning_rate = trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True)\n",
    "    xgb_max_depth = trial.suggest_int('xgb_max_depth', 3, 10)\n",
    "    xgb_subsample = trial.suggest_float('xgb_subsample', 0.6, 1.0)\n",
    "    xgb_colsample_bytree = trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0)\n",
    "    \n",
    "    # Hyperparameters for Logistic Regression\n",
    "    log_reg_C = trial.suggest_float('log_reg_C', 0.01, 10.0, log=True)\n",
    "    log_reg_solver = trial.suggest_categorical('log_reg_solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "    \n",
    "    # Hyperparameters for final estimator (Random Forest)\n",
    "    final_rf_n_estimators = trial.suggest_int('final_rf_n_estimators', 50, 300)\n",
    "    final_rf_max_depth = trial.suggest_int('final_rf_max_depth', 3, 20)\n",
    "    \n",
    "    # Define models with the suggested hyperparameters\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=rf_n_estimators,\n",
    "        max_depth=rf_max_depth,\n",
    "        min_samples_split=rf_min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        n_estimators=xgb_n_estimators,\n",
    "        learning_rate=xgb_learning_rate,\n",
    "        max_depth=xgb_max_depth,\n",
    "        subsample=xgb_subsample,\n",
    "        colsample_bytree=xgb_colsample_bytree,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    log_reg = LogisticRegression(\n",
    "        C=log_reg_C,\n",
    "        solver=log_reg_solver,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    lda_clf = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    final_estimator = RandomForestClassifier(\n",
    "        n_estimators=final_rf_n_estimators,\n",
    "        max_depth=final_rf_max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the stacking model\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[(\"RandomForest\", rf_clf), (\"XGBoost\", xgb_clf), (\"LogReg\", log_reg), (\"LDA\", lda_clf)],\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        stacking_clf.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = stacking_clf.predict(X_val_fold)\n",
    "        score = f1_score(y_val_fold, y_pred, average='weighted')\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Run Optuna optimization for Ensemble Model\n",
    "print(\"Optimizing Ensemble Model...\")\n",
    "study_ensemble = optuna.create_study(direction='maximize')\n",
    "study_ensemble.optimize(objective_ensemble, n_trials=50)  # Adjust n_trials as needed\n",
    "\n",
    "print(\"Best trial for Ensemble Model:\")\n",
    "print(f\"  Value: {study_ensemble.best_value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in study_ensemble.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Run Optuna optimization for Stacking Model\n",
    "print(\"\\nOptimizing Stacking Model...\")\n",
    "study_stacking = optuna.create_study(direction='maximize')\n",
    "study_stacking.optimize(objective_stacking, n_trials=50)  # Adjust n_trials as needed\n",
    "\n",
    "print(\"Best trial for Stacking Model:\")\n",
    "print(f\"  Value: {study_stacking.best_value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in study_stacking.best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Create and train the best Ensemble Model\n",
    "best_rf_ensemble = RandomForestClassifier(\n",
    "    n_estimators=study_ensemble.best_params['rf_n_estimators'],\n",
    "    max_depth=study_ensemble.best_params['rf_max_depth'],\n",
    "    min_samples_split=study_ensemble.best_params['rf_min_samples_split'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_xgb_ensemble = xgb.XGBClassifier(\n",
    "    n_estimators=study_ensemble.best_params['xgb_n_estimators'],\n",
    "    learning_rate=study_ensemble.best_params['xgb_learning_rate'],\n",
    "    max_depth=study_ensemble.best_params['xgb_max_depth'],\n",
    "    subsample=study_ensemble.best_params['xgb_subsample'],\n",
    "    colsample_bytree=study_ensemble.best_params['xgb_colsample_bytree'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_log_reg_ensemble = LogisticRegression(\n",
    "    C=study_ensemble.best_params['log_reg_C'],\n",
    "    solver=study_ensemble.best_params['log_reg_solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_lda_ensemble = LinearDiscriminantAnalysis()\n",
    "\n",
    "best_ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomForest\", best_rf_ensemble), \n",
    "        (\"XGBoost\", best_xgb_ensemble), \n",
    "        (\"LogReg\", best_log_reg_ensemble), \n",
    "        (\"LDA\", best_lda_ensemble)\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "# Create and train the best Stacking Model\n",
    "best_rf_stacking = RandomForestClassifier(\n",
    "    n_estimators=study_stacking.best_params['rf_n_estimators'],\n",
    "    max_depth=study_stacking.best_params['rf_max_depth'],\n",
    "    min_samples_split=study_stacking.best_params['rf_min_samples_split'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_xgb_stacking = xgb.XGBClassifier(\n",
    "    n_estimators=study_stacking.best_params['xgb_n_estimators'],\n",
    "    learning_rate=study_stacking.best_params['xgb_learning_rate'],\n",
    "    max_depth=study_stacking.best_params['xgb_max_depth'],\n",
    "    subsample=study_stacking.best_params['xgb_subsample'],\n",
    "    colsample_bytree=study_stacking.best_params['xgb_colsample_bytree'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_log_reg_stacking = LogisticRegression(\n",
    "    C=study_stacking.best_params['log_reg_C'],\n",
    "    solver=study_stacking.best_params['log_reg_solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_lda_stacking = LinearDiscriminantAnalysis()\n",
    "\n",
    "best_final_estimator = RandomForestClassifier(\n",
    "    n_estimators=study_stacking.best_params['final_rf_n_estimators'],\n",
    "    max_depth=study_stacking.best_params['final_rf_max_depth'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"RandomForest\", best_rf_stacking), \n",
    "        (\"XGBoost\", best_xgb_stacking), \n",
    "        (\"LogReg\", best_log_reg_stacking), \n",
    "        (\"LDA\", best_lda_stacking)\n",
    "    ],\n",
    "    final_estimator=best_final_estimator,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train the best models\n",
    "print(\"\\nTraining best models...\")\n",
    "best_ensemble_model.fit(X_train, y_train)\n",
    "best_stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best models\n",
    "y_pred_best_ensemble = best_ensemble_model.predict(X_test)\n",
    "y_pred_best_stacking = best_stacking_model.predict(X_test)\n",
    "\n",
    "accuracy_best_ensemble = accuracy_score(y_test, y_pred_best_ensemble)\n",
    "accuracy_best_stacking = accuracy_score(y_test, y_pred_best_stacking)\n",
    "\n",
    "report_best_ensemble = classification_report(y_test, y_pred_best_ensemble)\n",
    "report_best_stacking = classification_report(y_test, y_pred_best_stacking)\n",
    "\n",
    "print(f\"\\nBest Ensemble Model Accuracy with LDA: {accuracy_best_ensemble:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_best_ensemble)\n",
    "\n",
    "print(f\"\\nBest Stacking Model Accuracy with LDA: {accuracy_best_stacking:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_best_stacking)\n",
    "\n",
    "# Visualize Optuna results\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_optimization_history(study_ensemble)\n",
    "plt.title(\"Optimization History (Ensemble)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_param_importances(study_ensemble)\n",
    "plt.title(\"Parameter Importances (Ensemble)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('ensemble_optuna_results.png')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_optimization_history(study_stacking)\n",
    "plt.title(\"Optimization History (Stacking)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_param_importances(study_stacking)\n",
    "plt.title(\"Parameter Importances (Stacking)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('stacking_optuna_results.png')\n",
    "\n",
    "print(\"\\nOptimization plots saved as 'ensemble_optuna_results.png' and 'stacking_optuna_results.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_stacking_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save ensemble model\n",
    "joblib.dump(best_ensemble_model, \"best_ensemble_model.pkl\")\n",
    "\n",
    "# Save stacking model\n",
    "joblib.dump(best_stacking_model, \"best_stacking_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial for Ensemble Model:\n",
    "  Value: 0.9543\n",
    "  Params: \n",
    "    rf_n_estimators: 124\n",
    "    rf_max_depth: 8\n",
    "    rf_min_samples_split: 2\n",
    "    xgb_n_estimators: 227\n",
    "    xgb_learning_rate: 0.02411785491398546\n",
    "    xgb_max_depth: 10\n",
    "    xgb_subsample: 0.9173229807998943\n",
    "    xgb_colsample_bytree: 0.9809914380784289\n",
    "    log_reg_C: 0.03053110065048662\n",
    "    log_reg_solver: liblinear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
